{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "334b0dfb-e7e3-4d78-94b1-0132c3842349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README_Training_Notebooks.ipynb\n",
      "__pycache__\n",
      "audio_utils.py\n",
      "cuda_12.4.0_550.54.14_linux.run\n",
      "data\n",
      "external_repos\n",
      "liquidS4_audio.py\n",
      "liquid_s4_best.pth\n",
      "mamba_audio.py\n",
      "mamba_best.pth\n",
      "mamba_ssm-2.2.5+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl\n",
      "old_vjepa_model_trained\n",
      "train_liquid_s4.ipynb\n",
      "train_mamba.ipynb\n",
      "train_vjepa2.ipynb\n",
      "vjepa2_best.pth\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15857f6b-2e54-4177-bfa8-de536bd04dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/audio-classifier-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd audio-classifier-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dc04d-fc50-4970-be26-7ea8317c13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=external_repos/vjepa2:external_repos/vjepa2/src:.\n",
    "%env PYTHONPATH=/workspace/python_packages:$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba46db03-1f2c-4da6-b65c-ce96769eee38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-1.0.20-py3-none-any.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.3)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.24.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
      "Downloading timm-1.0.20-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm\n",
      "Successfully installed timm-1.0.20\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5734f129-d9af-4c07-abca-4ed5df4310c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=/workspace/audio-classifier-v2:/workspace/audio-classifier-v2/external_repos/vjepa2\n",
      "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "🚀 Training V-JEPA2 Audio Classifier on cuda\n",
      "🚀 Training V-JEPA2 with 15,966,002 parameters\n",
      "Epoch 1/150 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.77it/s]\n",
      "Epoch 1: TrainLoss=3.5996  ValAcc=0.0625  F1=0.0235  Prec=0.0169  Rec=0.0625\n",
      "💾 New best model saved (ValAcc=0.0625)\n",
      "Epoch 2/150 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.61it/s]\n",
      "Epoch 2: TrainLoss=3.3715  ValAcc=0.1000  F1=0.0523  Prec=0.0394  Rec=0.1000\n",
      "💾 New best model saved (ValAcc=0.1000)\n",
      "Epoch 3/150 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 12.00it/s]\n",
      "Epoch 3: TrainLoss=3.0598  ValAcc=0.1175  F1=0.0793  Prec=0.0998  Rec=0.1175\n",
      "💾 New best model saved (ValAcc=0.1175)\n",
      "Epoch 4/150 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 4: TrainLoss=2.6465  ValAcc=0.1650  F1=0.1241  Prec=0.1438  Rec=0.1650\n",
      "💾 New best model saved (ValAcc=0.1650)\n",
      "Epoch 5/150 [Train]: 100%|████████████████████| 113/113 [00:10<00:00, 11.20it/s]\n",
      "Epoch 5: TrainLoss=2.3232  ValAcc=0.2275  F1=0.1891  Prec=0.2443  Rec=0.2275\n",
      "💾 New best model saved (ValAcc=0.2275)\n",
      "Epoch 6/150 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 6: TrainLoss=2.0830  ValAcc=0.2350  F1=0.2031  Prec=0.2535  Rec=0.2350\n",
      "💾 New best model saved (ValAcc=0.2350)\n",
      "Epoch 7/150 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 7: TrainLoss=1.7612  ValAcc=0.3075  F1=0.2590  Prec=0.3225  Rec=0.3075\n",
      "💾 New best model saved (ValAcc=0.3075)\n",
      "Epoch 8/150 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.96it/s]\n",
      "Epoch 8: TrainLoss=1.5192  ValAcc=0.3375  F1=0.2924  Prec=0.3528  Rec=0.3375\n",
      "💾 New best model saved (ValAcc=0.3375)\n",
      "Epoch 9/150 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 12.02it/s]\n",
      "Epoch 9: TrainLoss=1.3491  ValAcc=0.3350  F1=0.2893  Prec=0.3338  Rec=0.3350\n",
      "Epoch 10/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 10: TrainLoss=1.1833  ValAcc=0.3575  F1=0.3125  Prec=0.3665  Rec=0.3575\n",
      "💾 New best model saved (ValAcc=0.3575)\n",
      "Epoch 11/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.68it/s]\n",
      "Epoch 11: TrainLoss=1.0179  ValAcc=0.3600  F1=0.3243  Prec=0.3894  Rec=0.3600\n",
      "💾 New best model saved (ValAcc=0.3600)\n",
      "Epoch 12/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 12: TrainLoss=0.9536  ValAcc=0.3700  F1=0.3388  Prec=0.4083  Rec=0.3700\n",
      "💾 New best model saved (ValAcc=0.3700)\n",
      "Epoch 13/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 13: TrainLoss=0.8170  ValAcc=0.4025  F1=0.3787  Prec=0.4576  Rec=0.4025\n",
      "💾 New best model saved (ValAcc=0.4025)\n",
      "Epoch 14/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.65it/s]\n",
      "Epoch 14: TrainLoss=0.7508  ValAcc=0.4275  F1=0.3951  Prec=0.4662  Rec=0.4275\n",
      "💾 New best model saved (ValAcc=0.4275)\n",
      "Epoch 15/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 15: TrainLoss=0.7070  ValAcc=0.3925  F1=0.3656  Prec=0.4433  Rec=0.3925\n",
      "Epoch 16/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 16: TrainLoss=0.5821  ValAcc=0.4425  F1=0.4175  Prec=0.4840  Rec=0.4425\n",
      "💾 New best model saved (ValAcc=0.4425)\n",
      "Epoch 17/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 17: TrainLoss=0.5767  ValAcc=0.4000  F1=0.3698  Prec=0.4391  Rec=0.4000\n",
      "Epoch 18/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.97it/s]\n",
      "Epoch 18: TrainLoss=0.4785  ValAcc=0.4225  F1=0.3897  Prec=0.4787  Rec=0.4225\n",
      "Epoch 19/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 19: TrainLoss=0.4636  ValAcc=0.4300  F1=0.4118  Prec=0.4690  Rec=0.4300\n",
      "Epoch 20/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 20: TrainLoss=0.4556  ValAcc=0.4375  F1=0.4135  Prec=0.4664  Rec=0.4375\n",
      "Epoch 21/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 21: TrainLoss=0.4099  ValAcc=0.4450  F1=0.4322  Prec=0.4931  Rec=0.4450\n",
      "💾 New best model saved (ValAcc=0.4450)\n",
      "Epoch 22/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 22: TrainLoss=0.3708  ValAcc=0.4300  F1=0.4009  Prec=0.4631  Rec=0.4300\n",
      "Epoch 23/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 23: TrainLoss=0.3560  ValAcc=0.4550  F1=0.4332  Prec=0.5107  Rec=0.4550\n",
      "💾 New best model saved (ValAcc=0.4550)\n",
      "Epoch 24/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 24: TrainLoss=0.3572  ValAcc=0.4200  F1=0.3905  Prec=0.4587  Rec=0.4200\n",
      "Epoch 25/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 25: TrainLoss=0.3131  ValAcc=0.4100  F1=0.3754  Prec=0.4322  Rec=0.4100\n",
      "Epoch 26/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.95it/s]\n",
      "Epoch 26: TrainLoss=0.2932  ValAcc=0.4550  F1=0.4355  Prec=0.5032  Rec=0.4550\n",
      "Epoch 27/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.03it/s]\n",
      "Epoch 27: TrainLoss=0.2738  ValAcc=0.4875  F1=0.4623  Prec=0.5096  Rec=0.4875\n",
      "💾 New best model saved (ValAcc=0.4875)\n",
      "Epoch 28/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 28: TrainLoss=0.3167  ValAcc=0.4050  F1=0.3720  Prec=0.4462  Rec=0.4050\n",
      "Epoch 29/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 29: TrainLoss=0.2659  ValAcc=0.4575  F1=0.4245  Prec=0.4630  Rec=0.4575\n",
      "Epoch 30/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.77it/s]\n",
      "Epoch 30: TrainLoss=0.2900  ValAcc=0.4225  F1=0.3889  Prec=0.5067  Rec=0.4225\n",
      "Epoch 31/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 31: TrainLoss=0.2496  ValAcc=0.4175  F1=0.3939  Prec=0.4573  Rec=0.4175\n",
      "Epoch 32/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.04it/s]\n",
      "Epoch 32: TrainLoss=0.2381  ValAcc=0.4275  F1=0.4017  Prec=0.4743  Rec=0.4275\n",
      "Epoch 33/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 33: TrainLoss=0.2529  ValAcc=0.4475  F1=0.4217  Prec=0.4783  Rec=0.4475\n",
      "Epoch 34/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.69it/s]\n",
      "Epoch 34: TrainLoss=0.2334  ValAcc=0.4575  F1=0.4316  Prec=0.4696  Rec=0.4575\n",
      "Epoch 35/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 35: TrainLoss=0.2154  ValAcc=0.4450  F1=0.4206  Prec=0.4833  Rec=0.4450\n",
      "Epoch 36/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 36: TrainLoss=0.2194  ValAcc=0.4500  F1=0.4219  Prec=0.4884  Rec=0.4500\n",
      "Epoch 37/150 [Train]: 100%|███████████████████| 113/113 [00:10<00:00, 11.08it/s]\n",
      "Epoch 37: TrainLoss=0.2156  ValAcc=0.4500  F1=0.4168  Prec=0.4746  Rec=0.4500\n",
      "Epoch 38/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.03it/s]\n",
      "Epoch 38: TrainLoss=0.2079  ValAcc=0.4425  F1=0.4399  Prec=0.5368  Rec=0.4425\n",
      "Epoch 39/150 [Train]: 100%|███████████████████| 113/113 [00:10<00:00, 10.61it/s]\n",
      "Epoch 39: TrainLoss=0.1881  ValAcc=0.4700  F1=0.4501  Prec=0.5184  Rec=0.4700\n",
      "Epoch 40/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 40: TrainLoss=0.2005  ValAcc=0.4575  F1=0.4388  Prec=0.5317  Rec=0.4575\n",
      "Epoch 41/150 [Train]: 100%|███████████████████| 113/113 [00:10<00:00, 11.24it/s]\n",
      "Epoch 41: TrainLoss=0.1960  ValAcc=0.4725  F1=0.4462  Prec=0.4949  Rec=0.4725\n",
      "Epoch 42/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.61it/s]\n",
      "Epoch 42: TrainLoss=0.1918  ValAcc=0.4800  F1=0.4619  Prec=0.5293  Rec=0.4800\n",
      "Epoch 43/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 43: TrainLoss=0.1789  ValAcc=0.4600  F1=0.4214  Prec=0.4665  Rec=0.4600\n",
      "Epoch 44/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.62it/s]\n",
      "Epoch 44: TrainLoss=0.1735  ValAcc=0.4925  F1=0.4868  Prec=0.5756  Rec=0.4925\n",
      "💾 New best model saved (ValAcc=0.4925)\n",
      "Epoch 45/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.39it/s]\n",
      "Epoch 45: TrainLoss=0.1693  ValAcc=0.4900  F1=0.4783  Prec=0.5750  Rec=0.4900\n",
      "Epoch 46/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.43it/s]\n",
      "Epoch 46: TrainLoss=0.1529  ValAcc=0.4625  F1=0.4407  Prec=0.4921  Rec=0.4625\n",
      "Epoch 47/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.73it/s]\n",
      "Epoch 47: TrainLoss=0.1448  ValAcc=0.4750  F1=0.4631  Prec=0.5209  Rec=0.4750\n",
      "Epoch 48/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 48: TrainLoss=0.1580  ValAcc=0.5075  F1=0.4830  Prec=0.5341  Rec=0.5075\n",
      "💾 New best model saved (ValAcc=0.5075)\n",
      "Epoch 49/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.44it/s]\n",
      "Epoch 49: TrainLoss=0.1422  ValAcc=0.5100  F1=0.4880  Prec=0.5478  Rec=0.5100\n",
      "💾 New best model saved (ValAcc=0.5100)\n",
      "Epoch 50/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.74it/s]\n",
      "Epoch 50: TrainLoss=0.1353  ValAcc=0.4675  F1=0.4479  Prec=0.5317  Rec=0.4675\n",
      "Epoch 51/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.44it/s]\n",
      "Epoch 51: TrainLoss=0.1529  ValAcc=0.5050  F1=0.4893  Prec=0.5389  Rec=0.5050\n",
      "Epoch 52/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.44it/s]\n",
      "Epoch 52: TrainLoss=0.1462  ValAcc=0.5100  F1=0.4882  Prec=0.5560  Rec=0.5100\n",
      "Epoch 53/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.53it/s]\n",
      "Epoch 53: TrainLoss=0.1346  ValAcc=0.4900  F1=0.4628  Prec=0.5591  Rec=0.4900\n",
      "Epoch 54/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 54: TrainLoss=0.1291  ValAcc=0.4750  F1=0.4610  Prec=0.5277  Rec=0.4750\n",
      "Epoch 55/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.74it/s]\n",
      "Epoch 55: TrainLoss=0.1336  ValAcc=0.4875  F1=0.4647  Prec=0.5153  Rec=0.4875\n",
      "Epoch 56/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.56it/s]\n",
      "Epoch 56: TrainLoss=0.1416  ValAcc=0.5025  F1=0.4765  Prec=0.5497  Rec=0.5025\n",
      "Epoch 57/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.56it/s]\n",
      "Epoch 57: TrainLoss=0.1426  ValAcc=0.5275  F1=0.5101  Prec=0.5648  Rec=0.5275\n",
      "💾 New best model saved (ValAcc=0.5275)\n",
      "Epoch 58/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.48it/s]\n",
      "Epoch 58: TrainLoss=0.1153  ValAcc=0.4725  F1=0.4498  Prec=0.5062  Rec=0.4725\n",
      "Epoch 59/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.34it/s]\n",
      "Epoch 59: TrainLoss=0.1122  ValAcc=0.4850  F1=0.4633  Prec=0.5403  Rec=0.4850\n",
      "Epoch 60/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.69it/s]\n",
      "Epoch 60: TrainLoss=0.1233  ValAcc=0.4775  F1=0.4567  Prec=0.5120  Rec=0.4775\n",
      "Epoch 61/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.52it/s]\n",
      "Epoch 61: TrainLoss=0.1086  ValAcc=0.4975  F1=0.4753  Prec=0.5235  Rec=0.4975\n",
      "Epoch 62/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.60it/s]\n",
      "Epoch 62: TrainLoss=0.1189  ValAcc=0.4750  F1=0.4552  Prec=0.4992  Rec=0.4750\n",
      "Epoch 63/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 63: TrainLoss=0.1090  ValAcc=0.4750  F1=0.4467  Prec=0.5127  Rec=0.4750\n",
      "Epoch 64/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 64: TrainLoss=0.1215  ValAcc=0.4900  F1=0.4677  Prec=0.5334  Rec=0.4900\n",
      "Epoch 65/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.91it/s]\n",
      "Epoch 65: TrainLoss=0.1131  ValAcc=0.5000  F1=0.4887  Prec=0.5738  Rec=0.5000\n",
      "Epoch 66/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.66it/s]\n",
      "Epoch 66: TrainLoss=0.0973  ValAcc=0.4825  F1=0.4611  Prec=0.5062  Rec=0.4825\n",
      "Epoch 67/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 67: TrainLoss=0.1060  ValAcc=0.4950  F1=0.4688  Prec=0.5108  Rec=0.4950\n",
      "Epoch 68/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.57it/s]\n",
      "Epoch 68: TrainLoss=0.0956  ValAcc=0.5200  F1=0.4973  Prec=0.5633  Rec=0.5200\n",
      "Epoch 69/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 69: TrainLoss=0.0800  ValAcc=0.4600  F1=0.4493  Prec=0.5227  Rec=0.4600\n",
      "Epoch 70/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 70: TrainLoss=0.0880  ValAcc=0.5000  F1=0.4746  Prec=0.5323  Rec=0.5000\n",
      "Epoch 71/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.64it/s]\n",
      "Epoch 71: TrainLoss=0.0971  ValAcc=0.4800  F1=0.4598  Prec=0.5039  Rec=0.4800\n",
      "Epoch 72/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 72: TrainLoss=0.1072  ValAcc=0.5375  F1=0.5174  Prec=0.5749  Rec=0.5375\n",
      "💾 New best model saved (ValAcc=0.5375)\n",
      "Epoch 73/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 73: TrainLoss=0.0902  ValAcc=0.5025  F1=0.4795  Prec=0.5390  Rec=0.5025\n",
      "Epoch 74/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.66it/s]\n",
      "Epoch 74: TrainLoss=0.0994  ValAcc=0.5100  F1=0.4902  Prec=0.5520  Rec=0.5100\n",
      "Epoch 75/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.68it/s]\n",
      "Epoch 75: TrainLoss=0.0771  ValAcc=0.5250  F1=0.5092  Prec=0.5646  Rec=0.5250\n",
      "Epoch 76/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 76: TrainLoss=0.0892  ValAcc=0.4800  F1=0.4531  Prec=0.5406  Rec=0.4800\n",
      "Epoch 77/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.58it/s]\n",
      "Epoch 77: TrainLoss=0.0757  ValAcc=0.4825  F1=0.4534  Prec=0.5255  Rec=0.4825\n",
      "Epoch 78/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.69it/s]\n",
      "Epoch 78: TrainLoss=0.0650  ValAcc=0.5000  F1=0.4861  Prec=0.5651  Rec=0.5000\n",
      "Epoch 79/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.71it/s]\n",
      "Epoch 79: TrainLoss=0.0620  ValAcc=0.4900  F1=0.4783  Prec=0.5684  Rec=0.4900\n",
      "Epoch 80/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.57it/s]\n",
      "Epoch 80: TrainLoss=0.0749  ValAcc=0.5100  F1=0.4889  Prec=0.5555  Rec=0.5100\n",
      "Epoch 81/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 81: TrainLoss=0.0700  ValAcc=0.4875  F1=0.4617  Prec=0.5085  Rec=0.4875\n",
      "Epoch 82/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.52it/s]\n",
      "Epoch 82: TrainLoss=0.0820  ValAcc=0.5350  F1=0.5168  Prec=0.5542  Rec=0.5350\n",
      "Epoch 83/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.64it/s]\n",
      "Epoch 83: TrainLoss=0.0527  ValAcc=0.5025  F1=0.4875  Prec=0.5443  Rec=0.5025\n",
      "Epoch 84/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 84: TrainLoss=0.0680  ValAcc=0.5175  F1=0.5000  Prec=0.5592  Rec=0.5175\n",
      "Epoch 85/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 85: TrainLoss=0.0676  ValAcc=0.5525  F1=0.5442  Prec=0.5921  Rec=0.5525\n",
      "💾 New best model saved (ValAcc=0.5525)\n",
      "Epoch 86/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.58it/s]\n",
      "Epoch 86: TrainLoss=0.0622  ValAcc=0.5325  F1=0.5209  Prec=0.5826  Rec=0.5325\n",
      "Epoch 87/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 87: TrainLoss=0.0549  ValAcc=0.5000  F1=0.4848  Prec=0.5316  Rec=0.5000\n",
      "Epoch 88/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 88: TrainLoss=0.0645  ValAcc=0.4750  F1=0.4544  Prec=0.5319  Rec=0.4750\n",
      "Epoch 89/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.59it/s]\n",
      "Epoch 89: TrainLoss=0.0562  ValAcc=0.5050  F1=0.4863  Prec=0.5532  Rec=0.5050\n",
      "Epoch 90/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 90: TrainLoss=0.0406  ValAcc=0.5150  F1=0.4921  Prec=0.5538  Rec=0.5150\n",
      "Epoch 91/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 91: TrainLoss=0.0596  ValAcc=0.4850  F1=0.4612  Prec=0.5275  Rec=0.4850\n",
      "Epoch 92/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 92: TrainLoss=0.0528  ValAcc=0.5075  F1=0.4825  Prec=0.5338  Rec=0.5075\n",
      "Epoch 93/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 93: TrainLoss=0.0449  ValAcc=0.5125  F1=0.4862  Prec=0.5268  Rec=0.5125\n",
      "Epoch 94/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 94: TrainLoss=0.0679  ValAcc=0.5100  F1=0.4743  Prec=0.5250  Rec=0.5100\n",
      "Epoch 95/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 95: TrainLoss=0.0498  ValAcc=0.5200  F1=0.5069  Prec=0.5725  Rec=0.5200\n",
      "Epoch 96/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.59it/s]\n",
      "Epoch 96: TrainLoss=0.0529  ValAcc=0.5225  F1=0.5113  Prec=0.5811  Rec=0.5225\n",
      "Epoch 97/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 97: TrainLoss=0.0634  ValAcc=0.5150  F1=0.5017  Prec=0.5575  Rec=0.5150\n",
      "Epoch 98/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 98: TrainLoss=0.0466  ValAcc=0.5200  F1=0.5060  Prec=0.6060  Rec=0.5200\n",
      "Epoch 99/150 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.57it/s]\n",
      "Epoch 99: TrainLoss=0.0449  ValAcc=0.5025  F1=0.4853  Prec=0.5818  Rec=0.5025\n",
      "Epoch 100/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 100: TrainLoss=0.0523  ValAcc=0.5325  F1=0.5138  Prec=0.5792  Rec=0.5325\n",
      "Epoch 101/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.97it/s]\n",
      "Epoch 101: TrainLoss=0.0433  ValAcc=0.5250  F1=0.5077  Prec=0.5646  Rec=0.5250\n",
      "Epoch 102/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.69it/s]\n",
      "Epoch 102: TrainLoss=0.0332  ValAcc=0.5250  F1=0.5115  Prec=0.5790  Rec=0.5250\n",
      "Epoch 103/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.55it/s]\n",
      "Epoch 103: TrainLoss=0.0388  ValAcc=0.5325  F1=0.5095  Prec=0.5903  Rec=0.5325\n",
      "Epoch 104/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.65it/s]\n",
      "Epoch 104: TrainLoss=0.0494  ValAcc=0.5300  F1=0.5077  Prec=0.5847  Rec=0.5300\n",
      "Epoch 105/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.63it/s]\n",
      "Epoch 105: TrainLoss=0.0458  ValAcc=0.5275  F1=0.5030  Prec=0.5586  Rec=0.5275\n",
      "Epoch 106/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.32it/s]\n",
      "Epoch 106: TrainLoss=0.0405  ValAcc=0.5050  F1=0.4836  Prec=0.5591  Rec=0.5050\n",
      "Epoch 107/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 107: TrainLoss=0.0403  ValAcc=0.5150  F1=0.4958  Prec=0.5701  Rec=0.5150\n",
      "Epoch 108/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.74it/s]\n",
      "Epoch 108: TrainLoss=0.0441  ValAcc=0.5225  F1=0.5031  Prec=0.5683  Rec=0.5225\n",
      "Epoch 109/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 109: TrainLoss=0.0337  ValAcc=0.5525  F1=0.5330  Prec=0.6063  Rec=0.5525\n",
      "Epoch 110/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 110: TrainLoss=0.0349  ValAcc=0.5450  F1=0.5329  Prec=0.6084  Rec=0.5450\n",
      "Epoch 111/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 111: TrainLoss=0.0367  ValAcc=0.5350  F1=0.5156  Prec=0.5624  Rec=0.5350\n",
      "Epoch 112/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 112: TrainLoss=0.0435  ValAcc=0.5325  F1=0.5110  Prec=0.5778  Rec=0.5325\n",
      "Epoch 113/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 113: TrainLoss=0.0440  ValAcc=0.5350  F1=0.5132  Prec=0.5842  Rec=0.5350\n",
      "Epoch 114/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 114: TrainLoss=0.0324  ValAcc=0.5250  F1=0.5000  Prec=0.5623  Rec=0.5250\n",
      "Epoch 115/150 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.69it/s]\n",
      "Epoch 115: TrainLoss=0.0383  ValAcc=0.5425  F1=0.5251  Prec=0.5765  Rec=0.5425\n",
      "⏹️ Early stopping at epoch 115\n",
      "🏆 Best Validation Accuracy: 0.5525\n",
      "🎯 Final V-JEPA2 Audio Classification Accuracy: 0.4750\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONPATH=/workspace/audio-classifier-v2:/workspace/audio-classifier-v2/external_repos/vjepa2\n",
    "\n",
    "!python external_repos/vjepa2/src/train_vjepa2.py \\\n",
    "  --esc50_path data/ESC-50 \\\n",
    "  --batch_size 32 \\\n",
    "  --workers 2 \\\n",
    "  --lr 1e-4 \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --epochs 150 \\\n",
    "  --patience 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c9c1f-d666-470e-a5db-822c6f4f3a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
