{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Classifier Training Notebooks\n",
        "\n",
        "This repository contains complete training notebooks for three state-of-the-art audio classification models:\n",
        "\n",
        "1. **Mamba Audio Classifier** (`train_mamba.ipynb`)\n",
        "2. **Liquid S4 Audio Classifier** (`train_liquid_s4.ipynb`) \n",
        "3. **V-JEPA2 Audio Classifier** (`train_vjepa2.ipynb`)\n",
        "\n",
        "All models are trained on the ESC-50 environmental sound classification dataset.\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "### Prerequisites\n",
        "- Python 3.8+\n",
        "- PyTorch 2.0+\n",
        "- CUDA-capable GPU (recommended)\n",
        "- ESC-50 dataset\n",
        "\n",
        "### Installation\n",
        "```bash\n",
        "# Install dependencies\n",
        "pip install torch torchaudio torchvision\n",
        "pip install tqdm matplotlib seaborn scikit-learn\n",
        "pip install pandas numpy\n",
        "\n",
        "# For Mamba\n",
        "pip install causal-conv1d>=1.0.0\n",
        "pip install mamba-ssm\n",
        "\n",
        "# For Liquid S4 (dependencies included in external_repos)\n",
        "# For V-JEPA2 (dependencies included in external_repos)\n",
        "```\n",
        "\n",
        "### Dataset Setup\n",
        "Download ESC-50 dataset and place it in the expected location:\n",
        "- **Expected location**: `./data/ESC-50/` (relative to the project root)\n",
        "- **Structure**: \n",
        "  ```\n",
        "  data/ESC-50/\n",
        "  ‚îú‚îÄ‚îÄ audio/          # .wav files\n",
        "  ‚îú‚îÄ‚îÄ meta/\n",
        "  ‚îÇ   ‚îî‚îÄ‚îÄ esc50.csv   # metadata\n",
        "  ‚îî‚îÄ‚îÄ README.md\n",
        "  ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Model Comparison\n",
        "\n",
        "| Model | Architecture | Input Format | Batch Size | Parameters | Memory Usage |\n",
        "|-------|-------------|--------------|------------|------------|--------------|\n",
        "| **Mamba** | State Space Model | Sequence [B, T, F] | 16 | ~50M | Medium |\n",
        "| **Liquid S4** | Liquid State Space | Sequence [B, T, F] | 32 | ~5M | Low |\n",
        "| **V-JEPA2** | Vision Transformer | Tubelets [B, C, T, H, W] | 8 | ~20M | High |\n",
        "\n",
        "### Key Differences:\n",
        "\n",
        "**Mamba Audio Classifier:**\n",
        "- Uses selective state space models for efficient sequence modeling\n",
        "- Processes mel-spectrograms as sequences\n",
        "- Good balance of performance and efficiency\n",
        "- Recommended for most use cases\n",
        "\n",
        "**Liquid S4 Audio Classifier:**\n",
        "- Uses liquid state space models with learnable kernels\n",
        "- Most parameter-efficient\n",
        "- Fastest training and inference\n",
        "- Good for resource-constrained environments\n",
        "\n",
        "**V-JEPA2 Audio Classifier:**\n",
        "- Treats audio as visual data using Vision Transformers\n",
        "- Uses tubelet tokenization for temporal modeling\n",
        "- Most memory-intensive but potentially highest accuracy\n",
        "- Best for high-performance requirements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Training Configuration\n",
        "\n",
        "### Common Features:\n",
        "- **Dataset**: ESC-50 (50 environmental sound classes)\n",
        "- **Input**: Mel-spectrograms (128 mel bins)\n",
        "- **Augmentation**: Time/frequency masking, noise, volume scaling\n",
        "- **Optimizer**: AdamW with weight decay\n",
        "- **Scheduler**: Cosine annealing learning rate\n",
        "- **Early Stopping**: Based on validation accuracy\n",
        "- **Evaluation**: Per-class metrics and confusion matrices\n",
        "\n",
        "### Model-Specific Configurations:\n",
        "\n",
        "#### Mamba Configuration:\n",
        "```python\n",
        "config = {\n",
        "    'batch_size': 16,\n",
        "    'learning_rate': 3e-4,\n",
        "    'epochs': 100,\n",
        "    'd_model': 512,\n",
        "    'n_layer': 12,\n",
        "    'pool_method': 'mean'\n",
        "}\n",
        "```\n",
        "\n",
        "#### Liquid S4 Configuration:\n",
        "```python\n",
        "config = {\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 1e-3,\n",
        "    'epochs': 150,\n",
        "    'd_model': 64,\n",
        "    'n_layers': 8,\n",
        "    'd_state': 64,\n",
        "    'dropout': 0.1\n",
        "}\n",
        "```\n",
        "\n",
        "#### V-JEPA2 Configuration:\n",
        "```python\n",
        "config = {\n",
        "    'batch_size': 8,\n",
        "    'learning_rate': 1e-4,\n",
        "    'epochs': 100,\n",
        "    'embed_dim': 384,\n",
        "    'depth': 8,\n",
        "    'num_heads': 8,\n",
        "    'patch_size': 16,\n",
        "    'tubelet_size': 2\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Usage Instructions\n",
        "\n",
        "### 1. Choose Your Model\n",
        "Select the notebook that best fits your requirements:\n",
        "- **For general use**: Start with `train_mamba.ipynb`\n",
        "- **For efficiency**: Use `train_liquid_s4.ipynb`\n",
        "- **For maximum performance**: Try `train_vjepa2.ipynb`\n",
        "\n",
        "### 2. Update Configuration\n",
        "Modify the configuration in Cell 2 of each notebook:\n",
        "```python\n",
        "# Adjust batch size based on your GPU memory\n",
        "config['batch_size'] = 16  # Reduce if OOM errors occur\n",
        "\n",
        "# Adjust model parameters if needed\n",
        "config['d_model'] = 256  # for smaller models\n",
        "```\n",
        "\n",
        "### 3. Run Training\n",
        "Execute cells sequentially:\n",
        "1. **Cell 1-2**: Setup and configuration\n",
        "2. **Cell 3**: Data loading and verification\n",
        "3. **Cell 4**: Model creation and testing\n",
        "4. **Cell 5**: Training setup\n",
        "5. **Cell 6**: Training loop (this will take time!)\n",
        "6. **Cell 7**: Test evaluation\n",
        "7. **Cell 8**: Results and visualization\n",
        "\n",
        "### 4. Monitor Training\n",
        "Each notebook includes:\n",
        "- Progress bars with real-time loss updates\n",
        "- Validation accuracy tracking\n",
        "- Early stopping to prevent overfitting\n",
        "- Model checkpointing (best model saved automatically)\n",
        "\n",
        "### 5. Analyze Results\n",
        "After training, you'll get:\n",
        "- Training/validation curves\n",
        "- Confusion matrix\n",
        "- Per-class performance metrics\n",
        "- Final test accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Troubleshooting\n",
        "\n",
        "### Common Issues:\n",
        "\n",
        "#### Out of Memory (OOM) Errors:\n",
        "```python\n",
        "# Reduce batch size\n",
        "config['batch_size'] = 8  # or even 4\n",
        "\n",
        "# Reduce model size\n",
        "config['d_model'] = 256  # for Mamba\n",
        "config['embed_dim'] = 192  # for V-JEPA2\n",
        "```\n",
        "\n",
        "#### Import Errors:\n",
        "```bash\n",
        "# Make sure external repos are properly set up\n",
        "# Check that external_repos/mamba, external_repos/liquid-s4, \n",
        "# and external_repos/vjepa2 directories exist\n",
        "```\n",
        "\n",
        "#### Dataset Path Issues:\n",
        "```python\n",
        "# Verify ESC-50 structure in data/ESC-50/:\n",
        "# data/ESC-50/\n",
        "#   ‚îú‚îÄ‚îÄ audio/          # .wav files\n",
        "#   ‚îú‚îÄ‚îÄ meta/\n",
        "#   ‚îÇ   ‚îî‚îÄ‚îÄ esc50.csv   # metadata\n",
        "#   ‚îî‚îÄ‚îÄ README.md\n",
        "```\n",
        "\n",
        "#### Slow Training:\n",
        "- Use GPU acceleration (CUDA)\n",
        "- Reduce `num_workers` in DataLoader\n",
        "- Use mixed precision training (add to training loop)\n",
        "\n",
        "### Performance Tips:\n",
        "\n",
        "1. **Start with Liquid S4** for fastest iteration\n",
        "2. **Use smaller models** for initial experiments\n",
        "3. **Monitor GPU memory** usage during training\n",
        "4. **Save checkpoints** regularly for long training runs\n",
        "5. **Use validation set** to tune hyperparameters\n",
        "\n",
        "### Expected Results:\n",
        "- **Mamba**: ~70-80% accuracy on ESC-50\n",
        "- **Liquid S4**: ~65-75% accuracy on ESC-50  \n",
        "- **V-JEPA2**: ~75-85% accuracy on ESC-50\n",
        "\n",
        "*Note: Results may vary based on hardware, hyperparameters, and random seeds.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ File Structure\n",
        "\n",
        "```\n",
        "audio-classifier-v2/\n",
        "‚îú‚îÄ‚îÄ train_mamba.ipynb              # Mamba training notebook\n",
        "‚îú‚îÄ‚îÄ train_liquid_s4.ipynb          # Liquid S4 training notebook  \n",
        "‚îú‚îÄ‚îÄ train_vjepa2.ipynb             # V-JEPA2 training notebook\n",
        "‚îú‚îÄ‚îÄ README_Training_Notebooks.ipynb # This documentation\n",
        "‚îú‚îÄ‚îÄ audio_utils.py                 # Data loading utilities (uses fixed path)\n",
        "‚îú‚îÄ‚îÄ mamba_audio.py                 # Mamba model implementation\n",
        "‚îú‚îÄ‚îÄ liquidS4_audio.py              # Liquid S4 model implementation\n",
        "‚îú‚îÄ‚îÄ vjepa2_audio.py                # V-JEPA2 model implementation\n",
        "‚îú‚îÄ‚îÄ data/                          # Dataset directory\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ ESC-50/                    # ESC-50 dataset (download here)\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ audio/                 # .wav files\n",
        "‚îÇ       ‚îú‚îÄ‚îÄ meta/\n",
        "‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ esc50.csv         # metadata\n",
        "‚îÇ       ‚îî‚îÄ‚îÄ README.md\n",
        "‚îî‚îÄ‚îÄ external_repos/                # External model repositories\n",
        "    ‚îú‚îÄ‚îÄ mamba/                     # Mamba SSM implementation\n",
        "    ‚îú‚îÄ‚îÄ liquid-s4/                 # Liquid S4 implementation\n",
        "    ‚îî‚îÄ‚îÄ vjepa2/                    # V-JEPA2 implementation\n",
        "```\n",
        "\n",
        "## üéØ Next Steps\n",
        "\n",
        "After training your models:\n",
        "\n",
        "1. **Compare Results**: Run all three notebooks and compare performance\n",
        "2. **Hyperparameter Tuning**: Experiment with different configurations\n",
        "3. **Model Ensemble**: Combine predictions from multiple models\n",
        "4. **Transfer Learning**: Fine-tune on your specific audio dataset\n",
        "5. **Deployment**: Export models for production use\n",
        "\n",
        "## üìö References\n",
        "\n",
        "- [Mamba: Linear-Time Sequence Modeling](https://arxiv.org/abs/2312.00752)\n",
        "- [Liquid S4: Liquid State Space Models](https://arxiv.org/abs/2306.03955)\n",
        "- [V-JEPA2: Video Joint Embedding Predictive Architecture](https://arxiv.org/abs/2402.01379)\n",
        "- [ESC-50 Dataset](https://github.com/karolpiczak/ESC-50)\n",
        "\n",
        "## ü§ù Contributing\n",
        "\n",
        "Feel free to:\n",
        "- Report issues or bugs\n",
        "- Suggest improvements\n",
        "- Add new model architectures\n",
        "- Optimize training configurations\n",
        "\n",
        "Happy training! üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
