{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9e7d3-9fda-484e-ae61-6e7df0635e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9afa0fc-e33c-4fab-9a70-55c85e97bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd audio-classifier-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee80352-86b6-4add-8c9c-48fba11250ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, '/workspace/audio-classifier-v2/external_repos/liquid-s4:external_repos/liquid-s4/src')\n",
    "# #!export PYTHONPATH=external_repos/liquid-s4:external_repos/liquid-s4/src:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69cc916-2981-4733-ac13-4a4d4ceb3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn tqdm pandas einops hydra-core opt_einsum rich soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe65ec2-b93f-4365-8aa6-d1da73fc8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y pytorch-lightning torchmetrics transformers\n",
    "!pip install pytorch-lightning==2.0.0 torchmetrics==0.11.4 transformers==4.33.2\n",
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d7dbe-8b2f-4efc-9511-6617f5dc386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TORCHAUDIO_SOUNDFILE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c4211-81aa-4513-83a5-29a2cbe76b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set environment variable in Python\n",
    "os.environ['PYTHONPATH'] = '/workspace/audio-classifier-v2'\n",
    "os.environ['PYTHONPATH'] = '/workspace/audio-classifier-v2/external_repos/liquid-s4'\n",
    "\n",
    "# Also add to sys.path for current session\n",
    "sys.path.insert(0, '/workspace/audio-classifier-v2')\n",
    "sys.path.insert(0, '/workspace/audio-classifier-v2/external_repos/liquid-s4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7021e77-99ea-477e-bb8a-6054368840a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=/workspace/audio-classifier-v2:/workspace/audio-classifier-v2/external_repos/liquid-s4\n",
      "CUDA extension for Cauchy multiplication not found. Install by going to extensions/cauchy/ and running `python setup.py install`. This should speed up end-to-end training by 10-50%\n",
      "Falling back on slow Cauchy kernel. Install at least one of pykeops or the CUDA extension for memory efficiency.\n",
      "Falling back on slow Vandermonde kernel. Install pykeops for improved memory efficiency.\n",
      "🚀 Training Liquid-S4 on cuda\n",
      "Instantiating layer '{'_name_': 's4', 'd_state': 64, 'l_max': None, 'channels': 1, 'bidirectional': False, 'activation': 'gelu', 'postact': 'glu', 'dropout': 0.0, 'mode': 'nplr', 'measure': 'legs', 'rank': 1, 'dt_min': 0.001, 'dt_max': 0.1, 'lr': {'dt': 0.001, 'A': 0.001, 'B': 0.001}, 'n_ssm': 1, 'liquid_kernel': None, 'liquid_degree': 2, 'allcombs': True, 'lcontract': None, 'deterministic': False, 'verbose': True, 'transposed': True}' within block\n",
      "Instantiating layer '{'d_state': 64, 'l_max': None, 'channels': 1, 'bidirectional': False, 'activation': 'gelu', 'postact': 'glu', 'dropout': 0.0, 'mode': 'nplr', 'measure': 'legs', 'rank': 1, 'dt_min': 0.001, 'dt_max': 0.1, 'lr': {'dt': 0.001, 'A': 0.001, 'B': 0.001}, 'n_ssm': 1, 'liquid_kernel': None, 'liquid_degree': 2, 'allcombs': True, 'lcontract': None, 'deterministic': False, 'verbose': True, 'transposed': True, '_name_': 's4'}' within block\n",
      "Instantiating layer '{'d_state': 64, 'l_max': None, 'channels': 1, 'bidirectional': False, 'activation': 'gelu', 'postact': 'glu', 'dropout': 0.0, 'mode': 'nplr', 'measure': 'legs', 'rank': 1, 'dt_min': 0.001, 'dt_max': 0.1, 'lr': {'dt': 0.001, 'A': 0.001, 'B': 0.001}, 'n_ssm': 1, 'liquid_kernel': None, 'liquid_degree': 2, 'allcombs': True, 'lcontract': None, 'deterministic': False, 'verbose': True, 'transposed': True, '_name_': 's4'}' within block\n",
      "Instantiating layer '{'d_state': 64, 'l_max': None, 'channels': 1, 'bidirectional': False, 'activation': 'gelu', 'postact': 'glu', 'dropout': 0.0, 'mode': 'nplr', 'measure': 'legs', 'rank': 1, 'dt_min': 0.001, 'dt_max': 0.1, 'lr': {'dt': 0.001, 'A': 0.001, 'B': 0.001}, 'n_ssm': 1, 'liquid_kernel': None, 'liquid_degree': 2, 'allcombs': True, 'lcontract': None, 'deterministic': False, 'verbose': True, 'transposed': True, '_name_': 's4'}' within block\n",
      "Instantiating layer '{'d_state': 64, 'l_max': None, 'channels': 1, 'bidirectional': False, 'activation': 'gelu', 'postact': 'glu', 'dropout': 0.0, 'mode': 'nplr', 'measure': 'legs', 'rank': 1, 'dt_min': 0.001, 'dt_max': 0.1, 'lr': {'dt': 0.001, 'A': 0.001, 'B': 0.001}, 'n_ssm': 1, 'liquid_kernel': None, 'liquid_degree': 2, 'allcombs': True, 'lcontract': None, 'deterministic': False, 'verbose': True, 'transposed': True, '_name_': 's4'}' within block\n",
      "Instantiating layer '{'d_state': 64, 'l_max': None, 'channels': 1, 'bidirectional': False, 'activation': 'gelu', 'postact': 'glu', 'dropout': 0.0, 'mode': 'nplr', 'measure': 'legs', 'rank': 1, 'dt_min': 0.001, 'dt_max': 0.1, 'lr': {'dt': 0.001, 'A': 0.001, 'B': 0.001}, 'n_ssm': 1, 'liquid_kernel': None, 'liquid_degree': 2, 'allcombs': True, 'lcontract': None, 'deterministic': False, 'verbose': True, 'transposed': True, '_name_': 's4'}' within block\n",
      "Instantiating layer '{'d_state': 64, 'l_max': None, 'channels': 1, 'bidirectional': False, 'activation': 'gelu', 'postact': 'glu', 'dropout': 0.0, 'mode': 'nplr', 'measure': 'legs', 'rank': 1, 'dt_min': 0.001, 'dt_max': 0.1, 'lr': {'dt': 0.001, 'A': 0.001, 'B': 0.001}, 'n_ssm': 1, 'liquid_kernel': None, 'liquid_degree': 2, 'allcombs': True, 'lcontract': None, 'deterministic': False, 'verbose': True, 'transposed': True, '_name_': 's4'}' within block\n",
      "Instantiating layer '{'d_state': 64, 'l_max': None, 'channels': 1, 'bidirectional': False, 'activation': 'gelu', 'postact': 'glu', 'dropout': 0.0, 'mode': 'nplr', 'measure': 'legs', 'rank': 1, 'dt_min': 0.001, 'dt_max': 0.1, 'lr': {'dt': 0.001, 'A': 0.001, 'B': 0.001}, 'n_ssm': 1, 'liquid_kernel': None, 'liquid_degree': 2, 'allcombs': True, 'lcontract': None, 'deterministic': False, 'verbose': True, 'transposed': True, '_name_': 's4'}' within block\n",
      "Epoch 1/180 [Train]: 100%|████████████████████| 113/113 [00:10<00:00, 11.14it/s]\n",
      "Epoch 1: TrainLoss=3.6793  ValAcc=0.1050  F1=0.0690  Prec=0.0901  Rec=0.1050\n",
      "💾 New best model saved (ValAcc=0.1050)\n",
      "Epoch 2/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.50it/s]\n",
      "Epoch 2: TrainLoss=3.3606  ValAcc=0.2225  F1=0.1691  Prec=0.1632  Rec=0.2225\n",
      "💾 New best model saved (ValAcc=0.2225)\n",
      "Epoch 3/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 3: TrainLoss=3.1548  ValAcc=0.2350  F1=0.1831  Prec=0.2183  Rec=0.2350\n",
      "💾 New best model saved (ValAcc=0.2350)\n",
      "Epoch 4/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.71it/s]\n",
      "Epoch 4: TrainLoss=2.9828  ValAcc=0.2800  F1=0.2239  Prec=0.2369  Rec=0.2800\n",
      "💾 New best model saved (ValAcc=0.2800)\n",
      "Epoch 5/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 5: TrainLoss=2.8448  ValAcc=0.2825  F1=0.2310  Prec=0.2473  Rec=0.2825\n",
      "💾 New best model saved (ValAcc=0.2825)\n",
      "Epoch 6/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.45it/s]\n",
      "Epoch 6: TrainLoss=2.7116  ValAcc=0.3250  F1=0.2730  Prec=0.2988  Rec=0.3250\n",
      "💾 New best model saved (ValAcc=0.3250)\n",
      "Epoch 7/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.55it/s]\n",
      "Epoch 7: TrainLoss=2.5965  ValAcc=0.3275  F1=0.2779  Prec=0.2896  Rec=0.3275\n",
      "💾 New best model saved (ValAcc=0.3275)\n",
      "Epoch 8/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 8: TrainLoss=2.4847  ValAcc=0.3400  F1=0.2900  Prec=0.2926  Rec=0.3400\n",
      "💾 New best model saved (ValAcc=0.3400)\n",
      "Epoch 9/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.64it/s]\n",
      "Epoch 9: TrainLoss=2.3656  ValAcc=0.3625  F1=0.3113  Prec=0.3231  Rec=0.3625\n",
      "💾 New best model saved (ValAcc=0.3625)\n",
      "Epoch 10/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 10: TrainLoss=2.2615  ValAcc=0.3750  F1=0.3286  Prec=0.3497  Rec=0.3750\n",
      "💾 New best model saved (ValAcc=0.3750)\n",
      "Epoch 11/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 11: TrainLoss=2.1721  ValAcc=0.3950  F1=0.3529  Prec=0.3743  Rec=0.3950\n",
      "💾 New best model saved (ValAcc=0.3950)\n",
      "Epoch 12/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.54it/s]\n",
      "Epoch 12: TrainLoss=2.0646  ValAcc=0.3825  F1=0.3408  Prec=0.3535  Rec=0.3825\n",
      "Epoch 13/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.36it/s]\n",
      "Epoch 13: TrainLoss=1.9783  ValAcc=0.4025  F1=0.3637  Prec=0.3981  Rec=0.4025\n",
      "💾 New best model saved (ValAcc=0.4025)\n",
      "Epoch 14/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 14: TrainLoss=1.8963  ValAcc=0.4000  F1=0.3667  Prec=0.4083  Rec=0.4000\n",
      "Epoch 15/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 15: TrainLoss=1.8010  ValAcc=0.4050  F1=0.3600  Prec=0.3661  Rec=0.4050\n",
      "💾 New best model saved (ValAcc=0.4050)\n",
      "Epoch 16/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.57it/s]\n",
      "Epoch 16: TrainLoss=1.7191  ValAcc=0.4400  F1=0.4044  Prec=0.4239  Rec=0.4400\n",
      "💾 New best model saved (ValAcc=0.4400)\n",
      "Epoch 17/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.63it/s]\n",
      "Epoch 17: TrainLoss=1.6404  ValAcc=0.4100  F1=0.3772  Prec=0.3852  Rec=0.4100\n",
      "Epoch 18/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.54it/s]\n",
      "Epoch 18: TrainLoss=1.5519  ValAcc=0.4175  F1=0.3837  Prec=0.4146  Rec=0.4175\n",
      "Epoch 19/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.61it/s]\n",
      "Epoch 19: TrainLoss=1.4837  ValAcc=0.4150  F1=0.3850  Prec=0.4026  Rec=0.4150\n",
      "Epoch 20/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 20: TrainLoss=1.4178  ValAcc=0.4250  F1=0.4001  Prec=0.4164  Rec=0.4250\n",
      "Epoch 21/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 21: TrainLoss=1.3503  ValAcc=0.4350  F1=0.4010  Prec=0.4197  Rec=0.4350\n",
      "Epoch 22/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 22: TrainLoss=1.2929  ValAcc=0.4250  F1=0.3937  Prec=0.3984  Rec=0.4250\n",
      "Epoch 23/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.58it/s]\n",
      "Epoch 23: TrainLoss=1.2349  ValAcc=0.4300  F1=0.4070  Prec=0.4242  Rec=0.4300\n",
      "Epoch 24/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.75it/s]\n",
      "Epoch 24: TrainLoss=1.1681  ValAcc=0.4175  F1=0.3962  Prec=0.4288  Rec=0.4175\n",
      "Epoch 25/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.63it/s]\n",
      "Epoch 25: TrainLoss=1.1058  ValAcc=0.4425  F1=0.4117  Prec=0.4272  Rec=0.4425\n",
      "💾 New best model saved (ValAcc=0.4425)\n",
      "Epoch 26/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 26: TrainLoss=1.0760  ValAcc=0.4175  F1=0.3980  Prec=0.4296  Rec=0.4175\n",
      "Epoch 27/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 27: TrainLoss=1.0127  ValAcc=0.4400  F1=0.4122  Prec=0.4424  Rec=0.4400\n",
      "Epoch 28/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 28: TrainLoss=0.9614  ValAcc=0.4375  F1=0.4137  Prec=0.4577  Rec=0.4375\n",
      "Epoch 29/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.73it/s]\n",
      "Epoch 29: TrainLoss=0.9157  ValAcc=0.4425  F1=0.4174  Prec=0.4373  Rec=0.4425\n",
      "Epoch 30/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 30: TrainLoss=0.8838  ValAcc=0.4450  F1=0.4185  Prec=0.4356  Rec=0.4450\n",
      "💾 New best model saved (ValAcc=0.4450)\n",
      "Epoch 31/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.66it/s]\n",
      "Epoch 31: TrainLoss=0.8420  ValAcc=0.4600  F1=0.4337  Prec=0.4695  Rec=0.4600\n",
      "💾 New best model saved (ValAcc=0.4600)\n",
      "Epoch 32/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 32: TrainLoss=0.7946  ValAcc=0.4625  F1=0.4313  Prec=0.4702  Rec=0.4625\n",
      "💾 New best model saved (ValAcc=0.4625)\n",
      "Epoch 33/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 33: TrainLoss=0.7567  ValAcc=0.4700  F1=0.4405  Prec=0.4571  Rec=0.4700\n",
      "💾 New best model saved (ValAcc=0.4700)\n",
      "Epoch 34/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 34: TrainLoss=0.7328  ValAcc=0.4650  F1=0.4372  Prec=0.4667  Rec=0.4650\n",
      "Epoch 35/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 35: TrainLoss=0.6973  ValAcc=0.4450  F1=0.4171  Prec=0.4571  Rec=0.4450\n",
      "Epoch 36/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.63it/s]\n",
      "Epoch 36: TrainLoss=0.6661  ValAcc=0.4425  F1=0.4203  Prec=0.4599  Rec=0.4425\n",
      "Epoch 37/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 37: TrainLoss=0.6424  ValAcc=0.4575  F1=0.4301  Prec=0.4550  Rec=0.4575\n",
      "Epoch 38/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.61it/s]\n",
      "Epoch 38: TrainLoss=0.6090  ValAcc=0.4600  F1=0.4282  Prec=0.4367  Rec=0.4600\n",
      "Epoch 39/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 39: TrainLoss=0.5942  ValAcc=0.4725  F1=0.4445  Prec=0.4524  Rec=0.4725\n",
      "💾 New best model saved (ValAcc=0.4725)\n",
      "Epoch 40/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 40: TrainLoss=0.5408  ValAcc=0.4700  F1=0.4471  Prec=0.4606  Rec=0.4700\n",
      "Epoch 41/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.56it/s]\n",
      "Epoch 41: TrainLoss=0.5340  ValAcc=0.4300  F1=0.4008  Prec=0.4639  Rec=0.4300\n",
      "Epoch 42/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.68it/s]\n",
      "Epoch 42: TrainLoss=0.5148  ValAcc=0.4725  F1=0.4435  Prec=0.4630  Rec=0.4725\n",
      "Epoch 43/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.53it/s]\n",
      "Epoch 43: TrainLoss=0.4940  ValAcc=0.4725  F1=0.4523  Prec=0.4743  Rec=0.4725\n",
      "Epoch 44/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.63it/s]\n",
      "Epoch 44: TrainLoss=0.4658  ValAcc=0.4775  F1=0.4458  Prec=0.4794  Rec=0.4775\n",
      "💾 New best model saved (ValAcc=0.4775)\n",
      "Epoch 45/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 45: TrainLoss=0.4576  ValAcc=0.4800  F1=0.4633  Prec=0.5058  Rec=0.4800\n",
      "💾 New best model saved (ValAcc=0.4800)\n",
      "Epoch 46/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 46: TrainLoss=0.4240  ValAcc=0.4600  F1=0.4403  Prec=0.4718  Rec=0.4600\n",
      "Epoch 47/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 47: TrainLoss=0.4217  ValAcc=0.4725  F1=0.4435  Prec=0.4573  Rec=0.4725\n",
      "Epoch 48/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.73it/s]\n",
      "Epoch 48: TrainLoss=0.3863  ValAcc=0.4775  F1=0.4575  Prec=0.4847  Rec=0.4775\n",
      "Epoch 49/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.59it/s]\n",
      "Epoch 49: TrainLoss=0.3731  ValAcc=0.4725  F1=0.4490  Prec=0.4839  Rec=0.4725\n",
      "Epoch 50/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.69it/s]\n",
      "Epoch 50: TrainLoss=0.3786  ValAcc=0.4600  F1=0.4378  Prec=0.4549  Rec=0.4600\n",
      "Epoch 51/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 51: TrainLoss=0.3312  ValAcc=0.4700  F1=0.4499  Prec=0.4867  Rec=0.4700\n",
      "Epoch 52/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.47it/s]\n",
      "Epoch 52: TrainLoss=0.3190  ValAcc=0.4550  F1=0.4394  Prec=0.4737  Rec=0.4550\n",
      "Epoch 53/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.71it/s]\n",
      "Epoch 53: TrainLoss=0.3152  ValAcc=0.4825  F1=0.4602  Prec=0.5065  Rec=0.4825\n",
      "💾 New best model saved (ValAcc=0.4825)\n",
      "Epoch 54/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.62it/s]\n",
      "Epoch 54: TrainLoss=0.3229  ValAcc=0.4650  F1=0.4391  Prec=0.4798  Rec=0.4650\n",
      "Epoch 55/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 55: TrainLoss=0.3108  ValAcc=0.4625  F1=0.4410  Prec=0.4848  Rec=0.4625\n",
      "Epoch 56/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 56: TrainLoss=0.2736  ValAcc=0.4550  F1=0.4282  Prec=0.4465  Rec=0.4550\n",
      "Epoch 57/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.60it/s]\n",
      "Epoch 57: TrainLoss=0.2720  ValAcc=0.4725  F1=0.4469  Prec=0.4614  Rec=0.4725\n",
      "Epoch 58/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.54it/s]\n",
      "Epoch 58: TrainLoss=0.2690  ValAcc=0.4750  F1=0.4596  Prec=0.4837  Rec=0.4750\n",
      "Epoch 59/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.41it/s]\n",
      "Epoch 59: TrainLoss=0.2497  ValAcc=0.4775  F1=0.4530  Prec=0.4829  Rec=0.4775\n",
      "Epoch 60/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.41it/s]\n",
      "Epoch 60: TrainLoss=0.2456  ValAcc=0.4850  F1=0.4634  Prec=0.4913  Rec=0.4850\n",
      "💾 New best model saved (ValAcc=0.4850)\n",
      "Epoch 61/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.37it/s]\n",
      "Epoch 61: TrainLoss=0.2447  ValAcc=0.4625  F1=0.4437  Prec=0.4799  Rec=0.4625\n",
      "Epoch 62/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.42it/s]\n",
      "Epoch 62: TrainLoss=0.2286  ValAcc=0.4600  F1=0.4378  Prec=0.4925  Rec=0.4600\n",
      "Epoch 63/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.46it/s]\n",
      "Epoch 63: TrainLoss=0.2270  ValAcc=0.4850  F1=0.4692  Prec=0.5174  Rec=0.4850\n",
      "Epoch 64/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.58it/s]\n",
      "Epoch 64: TrainLoss=0.1964  ValAcc=0.4850  F1=0.4612  Prec=0.4824  Rec=0.4850\n",
      "Epoch 65/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.66it/s]\n",
      "Epoch 65: TrainLoss=0.2174  ValAcc=0.4825  F1=0.4558  Prec=0.5038  Rec=0.4825\n",
      "Epoch 66/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.52it/s]\n",
      "Epoch 66: TrainLoss=0.1860  ValAcc=0.4475  F1=0.4141  Prec=0.4429  Rec=0.4475\n",
      "Epoch 67/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.71it/s]\n",
      "Epoch 67: TrainLoss=0.1924  ValAcc=0.4750  F1=0.4573  Prec=0.4843  Rec=0.4750\n",
      "Epoch 68/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.61it/s]\n",
      "Epoch 68: TrainLoss=0.1940  ValAcc=0.4675  F1=0.4433  Prec=0.4683  Rec=0.4675\n",
      "Epoch 69/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.42it/s]\n",
      "Epoch 69: TrainLoss=0.1866  ValAcc=0.4775  F1=0.4522  Prec=0.4835  Rec=0.4775\n",
      "Epoch 70/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.74it/s]\n",
      "Epoch 70: TrainLoss=0.1645  ValAcc=0.4800  F1=0.4619  Prec=0.4900  Rec=0.4800\n",
      "Epoch 71/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.75it/s]\n",
      "Epoch 71: TrainLoss=0.1750  ValAcc=0.4700  F1=0.4481  Prec=0.4729  Rec=0.4700\n",
      "Epoch 72/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.50it/s]\n",
      "Epoch 72: TrainLoss=0.1793  ValAcc=0.4625  F1=0.4355  Prec=0.4871  Rec=0.4625\n",
      "Epoch 73/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.38it/s]\n",
      "Epoch 73: TrainLoss=0.1867  ValAcc=0.4675  F1=0.4359  Prec=0.4599  Rec=0.4675\n",
      "Epoch 74/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 74: TrainLoss=0.1676  ValAcc=0.4575  F1=0.4302  Prec=0.4602  Rec=0.4575\n",
      "Epoch 75/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 75: TrainLoss=0.1524  ValAcc=0.4500  F1=0.4214  Prec=0.4367  Rec=0.4500\n",
      "Epoch 76/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 76: TrainLoss=0.1585  ValAcc=0.4675  F1=0.4476  Prec=0.4864  Rec=0.4675\n",
      "Epoch 77/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.79it/s]\n",
      "Epoch 77: TrainLoss=0.1446  ValAcc=0.4625  F1=0.4293  Prec=0.4486  Rec=0.4625\n",
      "Epoch 78/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 78: TrainLoss=0.1510  ValAcc=0.4950  F1=0.4698  Prec=0.5062  Rec=0.4950\n",
      "💾 New best model saved (ValAcc=0.4950)\n",
      "Epoch 79/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.79it/s]\n",
      "Epoch 79: TrainLoss=0.1352  ValAcc=0.4825  F1=0.4566  Prec=0.4935  Rec=0.4825\n",
      "Epoch 80/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.66it/s]\n",
      "Epoch 80: TrainLoss=0.1404  ValAcc=0.4900  F1=0.4676  Prec=0.5120  Rec=0.4900\n",
      "Epoch 81/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.62it/s]\n",
      "Epoch 81: TrainLoss=0.1407  ValAcc=0.4875  F1=0.4728  Prec=0.5207  Rec=0.4875\n",
      "Epoch 82/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 82: TrainLoss=0.1456  ValAcc=0.4900  F1=0.4633  Prec=0.5091  Rec=0.4900\n",
      "Epoch 83/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 83: TrainLoss=0.1267  ValAcc=0.4750  F1=0.4563  Prec=0.4902  Rec=0.4750\n",
      "Epoch 84/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 84: TrainLoss=0.1284  ValAcc=0.4825  F1=0.4645  Prec=0.4917  Rec=0.4825\n",
      "Epoch 85/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 85: TrainLoss=0.1263  ValAcc=0.4800  F1=0.4542  Prec=0.4785  Rec=0.4800\n",
      "Epoch 86/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.69it/s]\n",
      "Epoch 86: TrainLoss=0.1254  ValAcc=0.5025  F1=0.4798  Prec=0.5035  Rec=0.5025\n",
      "💾 New best model saved (ValAcc=0.5025)\n",
      "Epoch 87/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 87: TrainLoss=0.1305  ValAcc=0.4925  F1=0.4734  Prec=0.5163  Rec=0.4925\n",
      "Epoch 88/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 88: TrainLoss=0.1197  ValAcc=0.4825  F1=0.4687  Prec=0.5027  Rec=0.4825\n",
      "Epoch 89/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 89: TrainLoss=0.1246  ValAcc=0.4875  F1=0.4676  Prec=0.5039  Rec=0.4875\n",
      "Epoch 90/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.71it/s]\n",
      "Epoch 90: TrainLoss=0.1108  ValAcc=0.4725  F1=0.4481  Prec=0.4724  Rec=0.4725\n",
      "Epoch 91/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 91: TrainLoss=0.0977  ValAcc=0.4825  F1=0.4600  Prec=0.5070  Rec=0.4825\n",
      "Epoch 92/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.79it/s]\n",
      "Epoch 92: TrainLoss=0.1136  ValAcc=0.4800  F1=0.4621  Prec=0.4966  Rec=0.4800\n",
      "Epoch 93/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 93: TrainLoss=0.1130  ValAcc=0.4825  F1=0.4691  Prec=0.5137  Rec=0.4825\n",
      "Epoch 94/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.68it/s]\n",
      "Epoch 94: TrainLoss=0.1047  ValAcc=0.4775  F1=0.4583  Prec=0.4837  Rec=0.4775\n",
      "Epoch 95/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.91it/s]\n",
      "Epoch 95: TrainLoss=0.1070  ValAcc=0.4725  F1=0.4491  Prec=0.4846  Rec=0.4725\n",
      "Epoch 96/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.75it/s]\n",
      "Epoch 96: TrainLoss=0.1014  ValAcc=0.4700  F1=0.4419  Prec=0.4613  Rec=0.4700\n",
      "Epoch 97/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 97: TrainLoss=0.0959  ValAcc=0.4875  F1=0.4584  Prec=0.4793  Rec=0.4875\n",
      "Epoch 98/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.73it/s]\n",
      "Epoch 98: TrainLoss=0.0980  ValAcc=0.4800  F1=0.4592  Prec=0.4864  Rec=0.4800\n",
      "Epoch 99/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 99: TrainLoss=0.1062  ValAcc=0.4800  F1=0.4631  Prec=0.4887  Rec=0.4800\n",
      "Epoch 100/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 100: TrainLoss=0.0936  ValAcc=0.4850  F1=0.4541  Prec=0.4989  Rec=0.4850\n",
      "Epoch 101/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.74it/s]\n",
      "Epoch 101: TrainLoss=0.0894  ValAcc=0.4775  F1=0.4563  Prec=0.5009  Rec=0.4775\n",
      "Epoch 102/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 102: TrainLoss=0.0999  ValAcc=0.4925  F1=0.4749  Prec=0.5116  Rec=0.4925\n",
      "Epoch 103/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 103: TrainLoss=0.0840  ValAcc=0.4850  F1=0.4728  Prec=0.5169  Rec=0.4850\n",
      "Epoch 104/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 104: TrainLoss=0.1079  ValAcc=0.4675  F1=0.4418  Prec=0.4644  Rec=0.4675\n",
      "Epoch 105/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.77it/s]\n",
      "Epoch 105: TrainLoss=0.0838  ValAcc=0.4775  F1=0.4597  Prec=0.5046  Rec=0.4775\n",
      "Epoch 106/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.91it/s]\n",
      "Epoch 106: TrainLoss=0.0831  ValAcc=0.4800  F1=0.4624  Prec=0.5077  Rec=0.4800\n",
      "Epoch 107/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.68it/s]\n",
      "Epoch 107: TrainLoss=0.0905  ValAcc=0.4900  F1=0.4675  Prec=0.4906  Rec=0.4900\n",
      "Epoch 108/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 108: TrainLoss=0.0828  ValAcc=0.5050  F1=0.4835  Prec=0.5219  Rec=0.5050\n",
      "💾 New best model saved (ValAcc=0.5050)\n",
      "Epoch 109/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.49it/s]\n",
      "Epoch 109: TrainLoss=0.0935  ValAcc=0.4900  F1=0.4665  Prec=0.5060  Rec=0.4900\n",
      "Epoch 110/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 110: TrainLoss=0.0826  ValAcc=0.4975  F1=0.4682  Prec=0.4920  Rec=0.4975\n",
      "Epoch 111/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.74it/s]\n",
      "Epoch 111: TrainLoss=0.0775  ValAcc=0.5050  F1=0.4829  Prec=0.5329  Rec=0.5050\n",
      "Epoch 112/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 112: TrainLoss=0.0867  ValAcc=0.5050  F1=0.4759  Prec=0.5083  Rec=0.5050\n",
      "Epoch 113/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.65it/s]\n",
      "Epoch 113: TrainLoss=0.0857  ValAcc=0.4925  F1=0.4702  Prec=0.4941  Rec=0.4925\n",
      "Epoch 114/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 114: TrainLoss=0.0862  ValAcc=0.4775  F1=0.4570  Prec=0.4884  Rec=0.4775\n",
      "Epoch 115/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 115: TrainLoss=0.0720  ValAcc=0.4875  F1=0.4658  Prec=0.5116  Rec=0.4875\n",
      "Epoch 116/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 116: TrainLoss=0.0801  ValAcc=0.4975  F1=0.4738  Prec=0.5124  Rec=0.4975\n",
      "Epoch 117/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.61it/s]\n",
      "Epoch 117: TrainLoss=0.0744  ValAcc=0.4725  F1=0.4483  Prec=0.4706  Rec=0.4725\n",
      "Epoch 118/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 118: TrainLoss=0.0699  ValAcc=0.5000  F1=0.4729  Prec=0.4979  Rec=0.5000\n",
      "Epoch 119/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.77it/s]\n",
      "Epoch 119: TrainLoss=0.0786  ValAcc=0.5000  F1=0.4743  Prec=0.4948  Rec=0.5000\n",
      "Epoch 120/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 120: TrainLoss=0.0673  ValAcc=0.4800  F1=0.4576  Prec=0.4789  Rec=0.4800\n",
      "Epoch 121/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.66it/s]\n",
      "Epoch 121: TrainLoss=0.0728  ValAcc=0.4825  F1=0.4549  Prec=0.4772  Rec=0.4825\n",
      "Epoch 122/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.61it/s]\n",
      "Epoch 122: TrainLoss=0.0739  ValAcc=0.5000  F1=0.4762  Prec=0.4999  Rec=0.5000\n",
      "Epoch 123/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 123: TrainLoss=0.0692  ValAcc=0.4850  F1=0.4601  Prec=0.4894  Rec=0.4850\n",
      "Epoch 124/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.65it/s]\n",
      "Epoch 124: TrainLoss=0.0743  ValAcc=0.4900  F1=0.4627  Prec=0.4901  Rec=0.4900\n",
      "Epoch 125/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 125: TrainLoss=0.0815  ValAcc=0.4975  F1=0.4738  Prec=0.5119  Rec=0.4975\n",
      "Epoch 126/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 126: TrainLoss=0.0610  ValAcc=0.4900  F1=0.4673  Prec=0.4913  Rec=0.4900\n",
      "Epoch 127/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 127: TrainLoss=0.0802  ValAcc=0.4825  F1=0.4581  Prec=0.4971  Rec=0.4825\n",
      "Epoch 128/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 128: TrainLoss=0.0683  ValAcc=0.4825  F1=0.4541  Prec=0.4840  Rec=0.4825\n",
      "Epoch 129/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 129: TrainLoss=0.0642  ValAcc=0.4900  F1=0.4633  Prec=0.4996  Rec=0.4900\n",
      "Epoch 130/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.96it/s]\n",
      "Epoch 130: TrainLoss=0.0694  ValAcc=0.5200  F1=0.4951  Prec=0.5351  Rec=0.5200\n",
      "💾 New best model saved (ValAcc=0.5200)\n",
      "Epoch 131/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 131: TrainLoss=0.0662  ValAcc=0.5000  F1=0.4799  Prec=0.5086  Rec=0.5000\n",
      "Epoch 132/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 132: TrainLoss=0.0725  ValAcc=0.4975  F1=0.4790  Prec=0.5140  Rec=0.4975\n",
      "Epoch 133/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 133: TrainLoss=0.0658  ValAcc=0.5100  F1=0.4891  Prec=0.5185  Rec=0.5100\n",
      "Epoch 134/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 134: TrainLoss=0.0647  ValAcc=0.4975  F1=0.4711  Prec=0.5128  Rec=0.4975\n",
      "Epoch 135/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 135: TrainLoss=0.0734  ValAcc=0.5050  F1=0.4749  Prec=0.5001  Rec=0.5050\n",
      "Epoch 136/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 136: TrainLoss=0.0592  ValAcc=0.4900  F1=0.4588  Prec=0.4805  Rec=0.4900\n",
      "Epoch 137/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 137: TrainLoss=0.0733  ValAcc=0.5000  F1=0.4687  Prec=0.4993  Rec=0.5000\n",
      "Epoch 138/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 138: TrainLoss=0.0588  ValAcc=0.4950  F1=0.4686  Prec=0.4945  Rec=0.4950\n",
      "Epoch 139/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 139: TrainLoss=0.0619  ValAcc=0.4925  F1=0.4624  Prec=0.4859  Rec=0.4925\n",
      "Epoch 140/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.97it/s]\n",
      "Epoch 140: TrainLoss=0.0566  ValAcc=0.4975  F1=0.4737  Prec=0.4986  Rec=0.4975\n",
      "Epoch 141/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 141: TrainLoss=0.0591  ValAcc=0.4850  F1=0.4585  Prec=0.4809  Rec=0.4850\n",
      "Epoch 142/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 142: TrainLoss=0.0608  ValAcc=0.4850  F1=0.4625  Prec=0.4910  Rec=0.4850\n",
      "Epoch 143/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 143: TrainLoss=0.0588  ValAcc=0.5100  F1=0.4829  Prec=0.5195  Rec=0.5100\n",
      "Epoch 144/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.99it/s]\n",
      "Epoch 144: TrainLoss=0.0686  ValAcc=0.4875  F1=0.4597  Prec=0.4769  Rec=0.4875\n",
      "Epoch 145/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 145: TrainLoss=0.0655  ValAcc=0.5050  F1=0.4810  Prec=0.5141  Rec=0.5050\n",
      "Epoch 146/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.77it/s]\n",
      "Epoch 146: TrainLoss=0.0600  ValAcc=0.4950  F1=0.4704  Prec=0.4957  Rec=0.4950\n",
      "Epoch 147/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 147: TrainLoss=0.0582  ValAcc=0.4975  F1=0.4745  Prec=0.5007  Rec=0.4975\n",
      "Epoch 148/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 148: TrainLoss=0.0539  ValAcc=0.5025  F1=0.4771  Prec=0.5020  Rec=0.5025\n",
      "Epoch 149/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 149: TrainLoss=0.0641  ValAcc=0.5025  F1=0.4737  Prec=0.4991  Rec=0.5025\n",
      "Epoch 150/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.77it/s]\n",
      "Epoch 150: TrainLoss=0.0653  ValAcc=0.4950  F1=0.4712  Prec=0.5013  Rec=0.4950\n",
      "Epoch 151/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.68it/s]\n",
      "Epoch 151: TrainLoss=0.0609  ValAcc=0.4975  F1=0.4732  Prec=0.4976  Rec=0.4975\n",
      "Epoch 152/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 152: TrainLoss=0.0592  ValAcc=0.4950  F1=0.4630  Prec=0.5004  Rec=0.4950\n",
      "Epoch 153/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.65it/s]\n",
      "Epoch 153: TrainLoss=0.0551  ValAcc=0.4975  F1=0.4692  Prec=0.4907  Rec=0.4975\n",
      "Epoch 154/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.59it/s]\n",
      "Epoch 154: TrainLoss=0.0487  ValAcc=0.5000  F1=0.4765  Prec=0.5071  Rec=0.5000\n",
      "Epoch 155/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.97it/s]\n",
      "Epoch 155: TrainLoss=0.0643  ValAcc=0.4925  F1=0.4689  Prec=0.5055  Rec=0.4925\n",
      "Epoch 156/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 156: TrainLoss=0.0579  ValAcc=0.4950  F1=0.4673  Prec=0.4976  Rec=0.4950\n",
      "Epoch 157/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 157: TrainLoss=0.0639  ValAcc=0.4950  F1=0.4659  Prec=0.4947  Rec=0.4950\n",
      "Epoch 158/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 158: TrainLoss=0.0655  ValAcc=0.4975  F1=0.4656  Prec=0.4839  Rec=0.4975\n",
      "Epoch 159/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 159: TrainLoss=0.0524  ValAcc=0.5000  F1=0.4707  Prec=0.4937  Rec=0.5000\n",
      "Epoch 160/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.70it/s]\n",
      "Epoch 160: TrainLoss=0.0522  ValAcc=0.4975  F1=0.4671  Prec=0.4858  Rec=0.4975\n",
      "Epoch 161/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 161: TrainLoss=0.0548  ValAcc=0.5000  F1=0.4717  Prec=0.4945  Rec=0.5000\n",
      "Epoch 162/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 162: TrainLoss=0.0558  ValAcc=0.5000  F1=0.4711  Prec=0.4922  Rec=0.5000\n",
      "Epoch 163/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 163: TrainLoss=0.0575  ValAcc=0.4950  F1=0.4654  Prec=0.4837  Rec=0.4950\n",
      "Epoch 164/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 164: TrainLoss=0.0468  ValAcc=0.4950  F1=0.4658  Prec=0.4916  Rec=0.4950\n",
      "Epoch 165/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.79it/s]\n",
      "Epoch 165: TrainLoss=0.0490  ValAcc=0.4975  F1=0.4678  Prec=0.4923  Rec=0.4975\n",
      "Epoch 166/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 166: TrainLoss=0.0462  ValAcc=0.4925  F1=0.4641  Prec=0.4876  Rec=0.4925\n",
      "Epoch 167/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 167: TrainLoss=0.0551  ValAcc=0.4925  F1=0.4623  Prec=0.4805  Rec=0.4925\n",
      "Epoch 168/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 168: TrainLoss=0.0598  ValAcc=0.4925  F1=0.4634  Prec=0.4838  Rec=0.4925\n",
      "Epoch 169/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.75it/s]\n",
      "Epoch 169: TrainLoss=0.0568  ValAcc=0.4925  F1=0.4627  Prec=0.4830  Rec=0.4925\n",
      "Epoch 170/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 170: TrainLoss=0.0563  ValAcc=0.4925  F1=0.4637  Prec=0.4849  Rec=0.4925\n",
      "⏹️ Early stopping at epoch 170\n",
      "🏆 Best Validation Accuracy: 0.5200\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONPATH=/workspace/audio-classifier-v2:/workspace/audio-classifier-v2/external_repos/liquid-s4\n",
    "\n",
    "!python external_repos/liquid-s4/src/train_liquid_s4.py \\\n",
    "  --esc50_path data/ESC-50 \\\n",
    "  --batch_size 32 \\\n",
    "  --workers 2 \\\n",
    "  --lr 1e-4 \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --epochs 180 \\\n",
    "  --patience 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d79a5-8ba2-4bb8-8f1b-7fa00a91b37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
