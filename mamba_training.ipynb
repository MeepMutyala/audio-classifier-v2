{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5076a6a7-5b8d-411d-a573-442c15cc3e67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liquid-S4_training.ipynb\n",
      "audio-classifier-v2\n",
      "build_temp\n",
      "causal-conv1d\n",
      "cuda_12.4.0_550.54.14_linux.run\n",
      "mamba_ssm-2.2.5+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl\n",
      "mamba_ssm-2.2.5+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl.1\n",
      "mamba_training.ipynb\n",
      "python-packages\n",
      "python_packages\n",
      "tmp_build\n",
      "vjepa2_training.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5771b086-2123-42e0-a9c4-cf17ec4c06ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/audio-classifier-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd audio-classifier-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5cbea9b-46c8-4a4e-8610-50779ba9d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PYTHONPATH=\"/workspace/python_packages:$PYTHONPATH\"\n",
    "# !echo 'export PYTHONPATH=\"/workspace/python_packages:$PYTHONPATH\"' >> ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1699a1a2-8156-48a0-a05f-c90b450de8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mamba-ssm\n",
      "  Downloading mamba_ssm-2.2.5.tar.gz (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.8/113.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch (from mamba-ssm)\n",
      "  Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting triton (from mamba-ssm)\n",
      "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting ninja (from mamba-ssm)\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting einops (from mamba-ssm)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers (from mamba-ssm)\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging (from mamba-ssm)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting setuptools>=61.0.0 (from mamba-ssm)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch->mamba-ssm)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch->mamba-ssm)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch->mamba-ssm)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->mamba-ssm)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch->mamba-ssm)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch->mamba-ssm)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch->mamba-ssm)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers->mamba-ssm)\n",
      "  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers->mamba-ssm)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1 (from transformers->mamba-ssm)\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers->mamba-ssm)\n",
      "  Downloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests (from transformers->mamba-ssm)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers->mamba-ssm)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers->mamba-ssm)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers->mamba-ssm)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers->mamba-ssm)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->mamba-ssm)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->mamba-ssm)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers->mamba-ssm)\n",
      "  Downloading charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers->mamba-ssm)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers->mamba-ssm)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers->mamba-ssm)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.0/888.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.4/563.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.9/789.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: mamba-ssm\n",
      "  Building wheel for mamba-ssm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.5-cp310-cp310-linux_x86_64.whl size=532544326 sha256=c26869ce840efd96545eaac30633044ce1349125ca100e790d985bee4f55ca16\n",
      "  Stored in directory: /workspace/tmp_build/wheels/2c/50/92/d4aa767c1af23491e0a156fc0a247006b846c3ec61f30ce9a6\n",
      "Successfully built mamba-ssm\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, urllib3, typing-extensions, tqdm, sympy, setuptools, safetensors, regex, pyyaml, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, networkx, MarkupSafe, idna, hf-xet, fsspec, filelock, einops, charset_normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, huggingface-hub, torch, tokenizers, transformers, mamba-ssm\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !TMPDIR=/workspace/tmp_build pip install mamba-ssm --target /workspace/python_packages --no-cache-dir --cache-dir /workspace/tmp_build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904d4fd4-9074-460f-8b15-01ee0a483927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-22 12:29:23--  https://github.com/state-spaces/mamba/releases/download/v2.2.5/mamba_ssm-2.2.5+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl\n",
      "Resolving github.com (github.com)... 140.82.112.4\n",
      "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/725839295/494df944-c258-4721-bed5-e253d1772da2?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-22T13%3A19%3A23Z&rscd=attachment%3B+filename%3Dmamba_ssm-2.2.5%2Bcu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-22T12%3A18%3A54Z&ske=2025-09-22T13%3A19%3A23Z&sks=b&skv=2018-11-09&sig=CmFxQf%2B%2FYS4oxLvuVzha5Nr%2FMD%2Fsh%2FGie5H2PRJEQj4%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1ODU0NDQ2MywibmJmIjoxNzU4NTQ0MTYzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.OX_-p9Bbw4At1VSqmxyjbZHV6hWj_Mz0t3EdWoE7V4g&response-content-disposition=attachment%3B%20filename%3Dmamba_ssm-2.2.5%2Bcu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-09-22 12:29:23--  https://release-assets.githubusercontent.com/github-production-release-asset/725839295/494df944-c258-4721-bed5-e253d1772da2?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-09-22T13%3A19%3A23Z&rscd=attachment%3B+filename%3Dmamba_ssm-2.2.5%2Bcu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-09-22T12%3A18%3A54Z&ske=2025-09-22T13%3A19%3A23Z&sks=b&skv=2018-11-09&sig=CmFxQf%2B%2FYS4oxLvuVzha5Nr%2FMD%2Fsh%2FGie5H2PRJEQj4%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1ODU0NDQ2MywibmJmIjoxNzU4NTQ0MTYzLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.OX_-p9Bbw4At1VSqmxyjbZHV6hWj_Mz0t3EdWoE7V4g&response-content-disposition=attachment%3B%20filename%3Dmamba_ssm-2.2.5%2Bcu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 423837647 (404M) [application/octet-stream]\n",
      "Saving to: ‘mamba_ssm-2.2.5+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl’\n",
      "\n",
      "mamba_ssm-2.2.5+cu1 100%[===================>] 404.20M  54.0MB/s    in 7.5s    \n",
      "\n",
      "2025-09-22 12:29:31 (53.7 MB/s) - ‘mamba_ssm-2.2.5+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl’ saved [423837647/423837647]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/state-spaces/mamba/releases/download/v2.2.5/mamba_ssm-2.2.5+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8d19ee-ead2-433d-8d3f-a50c53b09bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./mamba_ssm-2.2.5+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl\n",
      "Installing collected packages: mamba-ssm\n",
      "Successfully installed mamba-ssm-2.2.5\n",
      "\u001b[33mWARNING: Target directory /workspace/python_packages/selective_scan_cuda.cpython-310-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/python_packages/mamba_ssm already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/python_packages/mamba_ssm-2.2.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mamba_ssm-2.2.5+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl --target /workspace/python_packages --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94bf96f0-1f2f-41cd-b675-3fa7e06bbc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'audio-classifier-v2'\n",
      "/workspace/audio-classifier-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd audio-classifier-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f266651c-8dc7-4a02-93ab-9a7c820ca8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python path includes workspace: True\n",
      "✓ PyTorch version: 2.1.0+cu118\n",
      "✓ CUDA available: True\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mamba_ssm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m✓ CUDA available:\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Test Mamba imports\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmamba_ssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixer_seq_simple\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MixerModel\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m✓ Mamba model import works\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Test CUDA extensions\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mamba_ssm'"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# print('Python path includes workspace:', any('workspace' in p for p in sys.path))\n",
    "\n",
    "# # Test PyTorch\n",
    "# import torch\n",
    "# print('✓ PyTorch version:', torch.__version__)\n",
    "# print('✓ CUDA available:', torch.cuda.is_available())\n",
    "\n",
    "# # Test Mamba imports\n",
    "# from mamba_ssm.models.mixer_seq_simple import MixerModel\n",
    "# print('✓ Mamba model import works')\n",
    "\n",
    "# # Test CUDA extensions\n",
    "# from mamba_ssm.ops.selective_scan_interface import selective_scan_fn\n",
    "# print('✓ CUDA extensions available')\n",
    "\n",
    "# print('All imports successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b5e15fe-c67f-4bc7-8e42-0e8cd55e034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting ninja\n",
      "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Installing collected packages: ninja\n",
      "Successfully installed ninja-1.13.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting triton==3.0.0\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting filelock (from triton==3.0.0)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m317.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: filelock, triton\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.1.0+cu118 requires triton==2.1.0, but you have triton 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filelock-3.19.1 triton-3.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install ninja\n",
    "!pip install triton==3.0.0 --target /workspace/python_packages --upgrade --force-reinstall --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d366f-d7ea-4868-be4d-5afd9dccc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PYTHONPATH=\"/workspace/python_packages:$PYTHONPATH\"\n",
    "# !python external_repos/mamba-code/train_mamba.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "187f669d-9ef5-4185-b86f-6a04b5ee2144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=/workspace/python_packages:$PYTHONPATH\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "🚀 Training Mamba on cuda\n",
      "🚀 Training Mamba with 7,394,354 parameters\n",
      "Epoch 1/180 [Train]: 100%|████████████████████| 113/113 [00:14<00:00,  7.61it/s]\n",
      "Epoch 1: TrainLoss=3.4365  ValAcc=0.1775  F1=0.1328  Prec=0.1857  Rec=0.1775\n",
      "💾 New best model saved (ValAcc=0.1775)\n",
      "Epoch 2/180 [Train]: 100%|████████████████████| 113/113 [00:10<00:00, 10.72it/s]\n",
      "Epoch 2: TrainLoss=2.5474  ValAcc=0.3525  F1=0.3195  Prec=0.3610  Rec=0.3525\n",
      "💾 New best model saved (ValAcc=0.3525)\n",
      "Epoch 3/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 3: TrainLoss=1.7825  ValAcc=0.4300  F1=0.3992  Prec=0.4337  Rec=0.4300\n",
      "💾 New best model saved (ValAcc=0.4300)\n",
      "Epoch 4/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.65it/s]\n",
      "Epoch 4: TrainLoss=1.1817  ValAcc=0.4375  F1=0.4147  Prec=0.4676  Rec=0.4375\n",
      "💾 New best model saved (ValAcc=0.4375)\n",
      "Epoch 5/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 5: TrainLoss=0.7979  ValAcc=0.4900  F1=0.4716  Prec=0.5245  Rec=0.4900\n",
      "💾 New best model saved (ValAcc=0.4900)\n",
      "Epoch 6/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.97it/s]\n",
      "Epoch 6: TrainLoss=0.5349  ValAcc=0.4750  F1=0.4460  Prec=0.4691  Rec=0.4750\n",
      "Epoch 7/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 12.05it/s]\n",
      "Epoch 7: TrainLoss=0.3352  ValAcc=0.4800  F1=0.4550  Prec=0.5000  Rec=0.4800\n",
      "Epoch 8/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 8: TrainLoss=0.2219  ValAcc=0.5175  F1=0.5010  Prec=0.5683  Rec=0.5175\n",
      "💾 New best model saved (ValAcc=0.5175)\n",
      "Epoch 9/180 [Train]: 100%|████████████████████| 113/113 [00:09<00:00, 11.95it/s]\n",
      "Epoch 9: TrainLoss=0.1515  ValAcc=0.5100  F1=0.4904  Prec=0.5401  Rec=0.5100\n",
      "Epoch 10/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 10: TrainLoss=0.1298  ValAcc=0.5350  F1=0.5049  Prec=0.5456  Rec=0.5350\n",
      "💾 New best model saved (ValAcc=0.5350)\n",
      "Epoch 11/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 11: TrainLoss=0.1117  ValAcc=0.5350  F1=0.5224  Prec=0.5576  Rec=0.5350\n",
      "Epoch 12/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 12: TrainLoss=0.0840  ValAcc=0.5200  F1=0.4898  Prec=0.5391  Rec=0.5200\n",
      "Epoch 13/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.05it/s]\n",
      "Epoch 13: TrainLoss=0.0612  ValAcc=0.5325  F1=0.5174  Prec=0.5441  Rec=0.5325\n",
      "Epoch 14/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.59it/s]\n",
      "Epoch 14: TrainLoss=0.0746  ValAcc=0.5025  F1=0.4878  Prec=0.5292  Rec=0.5025\n",
      "Epoch 15/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.61it/s]\n",
      "Epoch 15: TrainLoss=0.0681  ValAcc=0.5500  F1=0.5304  Prec=0.5621  Rec=0.5500\n",
      "💾 New best model saved (ValAcc=0.5500)\n",
      "Epoch 16/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.97it/s]\n",
      "Epoch 16: TrainLoss=0.0664  ValAcc=0.5300  F1=0.5075  Prec=0.5390  Rec=0.5300\n",
      "Epoch 17/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 17: TrainLoss=0.0416  ValAcc=0.5375  F1=0.5182  Prec=0.5620  Rec=0.5375\n",
      "Epoch 18/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.96it/s]\n",
      "Epoch 18: TrainLoss=0.0569  ValAcc=0.5550  F1=0.5397  Prec=0.5810  Rec=0.5550\n",
      "💾 New best model saved (ValAcc=0.5550)\n",
      "Epoch 19/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 19: TrainLoss=0.0386  ValAcc=0.5250  F1=0.5012  Prec=0.5454  Rec=0.5250\n",
      "Epoch 20/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 20: TrainLoss=0.0449  ValAcc=0.5350  F1=0.5128  Prec=0.5436  Rec=0.5350\n",
      "Epoch 21/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 21: TrainLoss=0.0395  ValAcc=0.5500  F1=0.5299  Prec=0.5631  Rec=0.5500\n",
      "Epoch 22/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 22: TrainLoss=0.0373  ValAcc=0.5175  F1=0.5016  Prec=0.5508  Rec=0.5175\n",
      "Epoch 23/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 23: TrainLoss=0.0390  ValAcc=0.5500  F1=0.5302  Prec=0.5574  Rec=0.5500\n",
      "Epoch 24/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 24: TrainLoss=0.0317  ValAcc=0.5325  F1=0.5074  Prec=0.5600  Rec=0.5325\n",
      "Epoch 25/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 25: TrainLoss=0.0361  ValAcc=0.5325  F1=0.5046  Prec=0.5298  Rec=0.5325\n",
      "Epoch 26/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 26: TrainLoss=0.0353  ValAcc=0.5425  F1=0.5255  Prec=0.5588  Rec=0.5425\n",
      "Epoch 27/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.95it/s]\n",
      "Epoch 27: TrainLoss=0.0244  ValAcc=0.5400  F1=0.5182  Prec=0.5655  Rec=0.5400\n",
      "Epoch 28/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 28: TrainLoss=0.0300  ValAcc=0.5525  F1=0.5343  Prec=0.5584  Rec=0.5525\n",
      "Epoch 29/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.08it/s]\n",
      "Epoch 29: TrainLoss=0.0248  ValAcc=0.5100  F1=0.4830  Prec=0.5328  Rec=0.5100\n",
      "Epoch 30/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.02it/s]\n",
      "Epoch 30: TrainLoss=0.0302  ValAcc=0.5450  F1=0.5201  Prec=0.5642  Rec=0.5450\n",
      "Epoch 31/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.44it/s]\n",
      "Epoch 31: TrainLoss=0.0302  ValAcc=0.5500  F1=0.5323  Prec=0.5812  Rec=0.5500\n",
      "Epoch 32/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.91it/s]\n",
      "Epoch 32: TrainLoss=0.0284  ValAcc=0.5375  F1=0.5054  Prec=0.5196  Rec=0.5375\n",
      "Epoch 33/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 33: TrainLoss=0.0308  ValAcc=0.5075  F1=0.4954  Prec=0.5484  Rec=0.5075\n",
      "Epoch 34/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 34: TrainLoss=0.0344  ValAcc=0.5175  F1=0.4905  Prec=0.5582  Rec=0.5175\n",
      "Epoch 35/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 35: TrainLoss=0.0297  ValAcc=0.5650  F1=0.5345  Prec=0.5811  Rec=0.5650\n",
      "💾 New best model saved (ValAcc=0.5650)\n",
      "Epoch 36/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.73it/s]\n",
      "Epoch 36: TrainLoss=0.0089  ValAcc=0.5475  F1=0.5253  Prec=0.5732  Rec=0.5475\n",
      "Epoch 37/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 37: TrainLoss=0.0255  ValAcc=0.5350  F1=0.5149  Prec=0.5826  Rec=0.5350\n",
      "Epoch 38/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.91it/s]\n",
      "Epoch 38: TrainLoss=0.0223  ValAcc=0.5375  F1=0.5299  Prec=0.6096  Rec=0.5375\n",
      "Epoch 39/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.98it/s]\n",
      "Epoch 39: TrainLoss=0.0265  ValAcc=0.5250  F1=0.5118  Prec=0.5745  Rec=0.5250\n",
      "Epoch 40/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.71it/s]\n",
      "Epoch 40: TrainLoss=0.0254  ValAcc=0.5150  F1=0.5045  Prec=0.5580  Rec=0.5150\n",
      "Epoch 41/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 41: TrainLoss=0.0257  ValAcc=0.5300  F1=0.5073  Prec=0.5494  Rec=0.5300\n",
      "Epoch 42/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 42: TrainLoss=0.0192  ValAcc=0.5125  F1=0.4926  Prec=0.5608  Rec=0.5125\n",
      "Epoch 43/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 43: TrainLoss=0.0207  ValAcc=0.5325  F1=0.5181  Prec=0.5747  Rec=0.5325\n",
      "Epoch 44/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 44: TrainLoss=0.0282  ValAcc=0.5725  F1=0.5553  Prec=0.5921  Rec=0.5725\n",
      "💾 New best model saved (ValAcc=0.5725)\n",
      "Epoch 45/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.03it/s]\n",
      "Epoch 45: TrainLoss=0.0127  ValAcc=0.5625  F1=0.5432  Prec=0.5801  Rec=0.5625\n",
      "Epoch 46/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 46: TrainLoss=0.0354  ValAcc=0.5425  F1=0.5256  Prec=0.5700  Rec=0.5425\n",
      "Epoch 47/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 47: TrainLoss=0.0206  ValAcc=0.5300  F1=0.5247  Prec=0.5727  Rec=0.5300\n",
      "Epoch 48/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 48: TrainLoss=0.0230  ValAcc=0.5575  F1=0.5510  Prec=0.6037  Rec=0.5575\n",
      "Epoch 49/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 49: TrainLoss=0.0191  ValAcc=0.5275  F1=0.5171  Prec=0.5919  Rec=0.5275\n",
      "Epoch 50/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 50: TrainLoss=0.0143  ValAcc=0.5275  F1=0.5213  Prec=0.5664  Rec=0.5275\n",
      "Epoch 51/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.69it/s]\n",
      "Epoch 51: TrainLoss=0.0095  ValAcc=0.5275  F1=0.5165  Prec=0.5847  Rec=0.5275\n",
      "Epoch 52/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 52: TrainLoss=0.0063  ValAcc=0.5575  F1=0.5401  Prec=0.5829  Rec=0.5575\n",
      "Epoch 53/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 53: TrainLoss=0.0148  ValAcc=0.5425  F1=0.5368  Prec=0.5774  Rec=0.5425\n",
      "Epoch 54/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 54: TrainLoss=0.0171  ValAcc=0.5450  F1=0.5274  Prec=0.5698  Rec=0.5450\n",
      "Epoch 55/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.63it/s]\n",
      "Epoch 55: TrainLoss=0.0242  ValAcc=0.5625  F1=0.5502  Prec=0.6030  Rec=0.5625\n",
      "Epoch 56/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 56: TrainLoss=0.0164  ValAcc=0.5525  F1=0.5540  Prec=0.6364  Rec=0.5525\n",
      "Epoch 57/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.97it/s]\n",
      "Epoch 57: TrainLoss=0.0134  ValAcc=0.5400  F1=0.5279  Prec=0.5954  Rec=0.5400\n",
      "Epoch 58/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 58: TrainLoss=0.0178  ValAcc=0.5400  F1=0.5252  Prec=0.5826  Rec=0.5400\n",
      "Epoch 59/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 59: TrainLoss=0.0160  ValAcc=0.5725  F1=0.5485  Prec=0.6004  Rec=0.5725\n",
      "Epoch 60/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.71it/s]\n",
      "Epoch 60: TrainLoss=0.0209  ValAcc=0.5550  F1=0.5356  Prec=0.5690  Rec=0.5550\n",
      "Epoch 61/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 61: TrainLoss=0.0235  ValAcc=0.5550  F1=0.5360  Prec=0.6336  Rec=0.5550\n",
      "Epoch 62/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 62: TrainLoss=0.0208  ValAcc=0.5525  F1=0.5299  Prec=0.5822  Rec=0.5525\n",
      "Epoch 63/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.64it/s]\n",
      "Epoch 63: TrainLoss=0.0122  ValAcc=0.5575  F1=0.5443  Prec=0.6010  Rec=0.5575\n",
      "Epoch 64/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.71it/s]\n",
      "Epoch 64: TrainLoss=0.0318  ValAcc=0.5800  F1=0.5665  Prec=0.6143  Rec=0.5800\n",
      "💾 New best model saved (ValAcc=0.5800)\n",
      "Epoch 65/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 65: TrainLoss=0.0097  ValAcc=0.5725  F1=0.5597  Prec=0.5971  Rec=0.5725\n",
      "Epoch 66/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.62it/s]\n",
      "Epoch 66: TrainLoss=0.0158  ValAcc=0.5675  F1=0.5528  Prec=0.5787  Rec=0.5675\n",
      "Epoch 67/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.62it/s]\n",
      "Epoch 67: TrainLoss=0.0076  ValAcc=0.5875  F1=0.5710  Prec=0.6102  Rec=0.5875\n",
      "💾 New best model saved (ValAcc=0.5875)\n",
      "Epoch 68/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.78it/s]\n",
      "Epoch 68: TrainLoss=0.0114  ValAcc=0.5875  F1=0.5686  Prec=0.6311  Rec=0.5875\n",
      "Epoch 69/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 69: TrainLoss=0.0145  ValAcc=0.5450  F1=0.5294  Prec=0.6015  Rec=0.5450\n",
      "Epoch 70/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.52it/s]\n",
      "Epoch 70: TrainLoss=0.0089  ValAcc=0.5750  F1=0.5652  Prec=0.6252  Rec=0.5750\n",
      "Epoch 71/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.91it/s]\n",
      "Epoch 71: TrainLoss=0.0078  ValAcc=0.5575  F1=0.5398  Prec=0.5750  Rec=0.5575\n",
      "Epoch 72/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.75it/s]\n",
      "Epoch 72: TrainLoss=0.0171  ValAcc=0.5800  F1=0.5627  Prec=0.6054  Rec=0.5800\n",
      "Epoch 73/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.74it/s]\n",
      "Epoch 73: TrainLoss=0.0187  ValAcc=0.5725  F1=0.5495  Prec=0.5588  Rec=0.5725\n",
      "Epoch 74/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.64it/s]\n",
      "Epoch 74: TrainLoss=0.0029  ValAcc=0.5500  F1=0.5316  Prec=0.5650  Rec=0.5500\n",
      "Epoch 75/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 75: TrainLoss=0.0227  ValAcc=0.5575  F1=0.5369  Prec=0.5620  Rec=0.5575\n",
      "Epoch 76/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.79it/s]\n",
      "Epoch 76: TrainLoss=0.0045  ValAcc=0.5400  F1=0.5246  Prec=0.5582  Rec=0.5400\n",
      "Epoch 77/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 77: TrainLoss=0.0171  ValAcc=0.5625  F1=0.5571  Prec=0.6061  Rec=0.5625\n",
      "Epoch 78/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.82it/s]\n",
      "Epoch 78: TrainLoss=0.0146  ValAcc=0.5275  F1=0.4931  Prec=0.5209  Rec=0.5275\n",
      "Epoch 79/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 79: TrainLoss=0.0089  ValAcc=0.5575  F1=0.5396  Prec=0.5792  Rec=0.5575\n",
      "Epoch 80/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 80: TrainLoss=0.0073  ValAcc=0.5575  F1=0.5396  Prec=0.6137  Rec=0.5575\n",
      "Epoch 81/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.02it/s]\n",
      "Epoch 81: TrainLoss=0.0136  ValAcc=0.5475  F1=0.5239  Prec=0.5695  Rec=0.5475\n",
      "Epoch 82/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 82: TrainLoss=0.0105  ValAcc=0.5400  F1=0.5241  Prec=0.5706  Rec=0.5400\n",
      "Epoch 83/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.96it/s]\n",
      "Epoch 83: TrainLoss=0.0105  ValAcc=0.5725  F1=0.5604  Prec=0.6190  Rec=0.5725\n",
      "Epoch 84/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.08it/s]\n",
      "Epoch 84: TrainLoss=0.0094  ValAcc=0.5775  F1=0.5686  Prec=0.6378  Rec=0.5775\n",
      "Epoch 85/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 85: TrainLoss=0.0127  ValAcc=0.5975  F1=0.5802  Prec=0.6253  Rec=0.5975\n",
      "💾 New best model saved (ValAcc=0.5975)\n",
      "Epoch 86/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.99it/s]\n",
      "Epoch 86: TrainLoss=0.0098  ValAcc=0.5725  F1=0.5510  Prec=0.6034  Rec=0.5725\n",
      "Epoch 87/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.96it/s]\n",
      "Epoch 87: TrainLoss=0.0146  ValAcc=0.5650  F1=0.5454  Prec=0.5955  Rec=0.5650\n",
      "Epoch 88/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.68it/s]\n",
      "Epoch 88: TrainLoss=0.0015  ValAcc=0.5700  F1=0.5605  Prec=0.6261  Rec=0.5700\n",
      "Epoch 89/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 89: TrainLoss=0.0061  ValAcc=0.5800  F1=0.5645  Prec=0.6327  Rec=0.5800\n",
      "Epoch 90/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 90: TrainLoss=0.0046  ValAcc=0.5625  F1=0.5357  Prec=0.5679  Rec=0.5625\n",
      "Epoch 91/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 91: TrainLoss=0.0022  ValAcc=0.5550  F1=0.5388  Prec=0.5843  Rec=0.5550\n",
      "Epoch 92/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.03it/s]\n",
      "Epoch 92: TrainLoss=0.0030  ValAcc=0.5625  F1=0.5513  Prec=0.6146  Rec=0.5625\n",
      "Epoch 93/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.95it/s]\n",
      "Epoch 93: TrainLoss=0.0037  ValAcc=0.5675  F1=0.5562  Prec=0.6018  Rec=0.5675\n",
      "Epoch 94/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.88it/s]\n",
      "Epoch 94: TrainLoss=0.0072  ValAcc=0.5600  F1=0.5474  Prec=0.6081  Rec=0.5600\n",
      "Epoch 95/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 95: TrainLoss=0.0152  ValAcc=0.5625  F1=0.5562  Prec=0.6054  Rec=0.5625\n",
      "Epoch 96/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 96: TrainLoss=0.0032  ValAcc=0.5675  F1=0.5577  Prec=0.6161  Rec=0.5675\n",
      "Epoch 97/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.07it/s]\n",
      "Epoch 97: TrainLoss=0.0020  ValAcc=0.5825  F1=0.5743  Prec=0.6258  Rec=0.5825\n",
      "Epoch 98/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 11.98it/s]\n",
      "Epoch 98: TrainLoss=0.0027  ValAcc=0.5800  F1=0.5679  Prec=0.6146  Rec=0.5800\n",
      "Epoch 99/180 [Train]: 100%|███████████████████| 113/113 [00:09<00:00, 12.16it/s]\n",
      "Epoch 99: TrainLoss=0.0097  ValAcc=0.5825  F1=0.5615  Prec=0.5998  Rec=0.5825\n",
      "Epoch 100/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 100: TrainLoss=0.0024  ValAcc=0.5950  F1=0.5769  Prec=0.6003  Rec=0.5950\n",
      "Epoch 101/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 101: TrainLoss=0.0109  ValAcc=0.5800  F1=0.5585  Prec=0.5968  Rec=0.5800\n",
      "Epoch 102/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.95it/s]\n",
      "Epoch 102: TrainLoss=0.0078  ValAcc=0.5750  F1=0.5596  Prec=0.6061  Rec=0.5750\n",
      "Epoch 103/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.96it/s]\n",
      "Epoch 103: TrainLoss=0.0011  ValAcc=0.5775  F1=0.5592  Prec=0.5988  Rec=0.5775\n",
      "Epoch 104/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.55it/s]\n",
      "Epoch 104: TrainLoss=0.0094  ValAcc=0.5900  F1=0.5778  Prec=0.6340  Rec=0.5900\n",
      "Epoch 105/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 105: TrainLoss=0.0049  ValAcc=0.5900  F1=0.5791  Prec=0.6303  Rec=0.5900\n",
      "Epoch 106/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 106: TrainLoss=0.0048  ValAcc=0.6025  F1=0.5928  Prec=0.6437  Rec=0.6025\n",
      "💾 New best model saved (ValAcc=0.6025)\n",
      "Epoch 107/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 107: TrainLoss=0.0055  ValAcc=0.5850  F1=0.5673  Prec=0.6228  Rec=0.5850\n",
      "Epoch 108/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.74it/s]\n",
      "Epoch 108: TrainLoss=0.0128  ValAcc=0.5900  F1=0.5797  Prec=0.6260  Rec=0.5900\n",
      "Epoch 109/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 109: TrainLoss=0.0030  ValAcc=0.5975  F1=0.5838  Prec=0.6303  Rec=0.5975\n",
      "Epoch 110/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 110: TrainLoss=0.0039  ValAcc=0.5700  F1=0.5583  Prec=0.6242  Rec=0.5700\n",
      "Epoch 111/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 111: TrainLoss=0.0034  ValAcc=0.5475  F1=0.5399  Prec=0.6050  Rec=0.5475\n",
      "Epoch 112/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 112: TrainLoss=0.0042  ValAcc=0.5875  F1=0.5787  Prec=0.6448  Rec=0.5875\n",
      "Epoch 113/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.87it/s]\n",
      "Epoch 113: TrainLoss=0.0023  ValAcc=0.5825  F1=0.5681  Prec=0.6345  Rec=0.5825\n",
      "Epoch 114/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 114: TrainLoss=0.0016  ValAcc=0.5850  F1=0.5763  Prec=0.6289  Rec=0.5850\n",
      "Epoch 115/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.68it/s]\n",
      "Epoch 115: TrainLoss=0.0035  ValAcc=0.5975  F1=0.5842  Prec=0.6330  Rec=0.5975\n",
      "Epoch 116/180 [Train]: 100%|██████████████████| 113/113 [00:10<00:00, 10.77it/s]\n",
      "Epoch 116: TrainLoss=0.0006  ValAcc=0.6100  F1=0.5975  Prec=0.6607  Rec=0.6100\n",
      "💾 New best model saved (ValAcc=0.6100)\n",
      "Epoch 117/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.94it/s]\n",
      "Epoch 117: TrainLoss=0.0033  ValAcc=0.5950  F1=0.5857  Prec=0.6443  Rec=0.5950\n",
      "Epoch 118/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 118: TrainLoss=0.0036  ValAcc=0.5900  F1=0.5681  Prec=0.6188  Rec=0.5900\n",
      "Epoch 119/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.24it/s]\n",
      "Epoch 119: TrainLoss=0.0009  ValAcc=0.6000  F1=0.5752  Prec=0.6252  Rec=0.6000\n",
      "Epoch 120/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.84it/s]\n",
      "Epoch 120: TrainLoss=0.0019  ValAcc=0.5875  F1=0.5680  Prec=0.6244  Rec=0.5875\n",
      "Epoch 121/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 121: TrainLoss=0.0050  ValAcc=0.5950  F1=0.5762  Prec=0.6371  Rec=0.5950\n",
      "Epoch 122/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.76it/s]\n",
      "Epoch 122: TrainLoss=0.0042  ValAcc=0.5850  F1=0.5719  Prec=0.6394  Rec=0.5850\n",
      "Epoch 123/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.93it/s]\n",
      "Epoch 123: TrainLoss=0.0043  ValAcc=0.5900  F1=0.5771  Prec=0.6273  Rec=0.5900\n",
      "Epoch 124/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.79it/s]\n",
      "Epoch 124: TrainLoss=0.0046  ValAcc=0.5925  F1=0.5775  Prec=0.6254  Rec=0.5925\n",
      "Epoch 125/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.02it/s]\n",
      "Epoch 125: TrainLoss=0.0006  ValAcc=0.5900  F1=0.5748  Prec=0.6361  Rec=0.5900\n",
      "Epoch 126/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 126: TrainLoss=0.0006  ValAcc=0.5900  F1=0.5744  Prec=0.6228  Rec=0.5900\n",
      "Epoch 127/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.01it/s]\n",
      "Epoch 127: TrainLoss=0.0007  ValAcc=0.5800  F1=0.5648  Prec=0.6111  Rec=0.5800\n",
      "Epoch 128/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.06it/s]\n",
      "Epoch 128: TrainLoss=0.0046  ValAcc=0.5625  F1=0.5430  Prec=0.5885  Rec=0.5625\n",
      "Epoch 129/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.01it/s]\n",
      "Epoch 129: TrainLoss=0.0053  ValAcc=0.5850  F1=0.5634  Prec=0.6114  Rec=0.5850\n",
      "Epoch 130/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 130: TrainLoss=0.0029  ValAcc=0.5750  F1=0.5574  Prec=0.5995  Rec=0.5750\n",
      "Epoch 131/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.14it/s]\n",
      "Epoch 131: TrainLoss=0.0005  ValAcc=0.5750  F1=0.5580  Prec=0.5993  Rec=0.5750\n",
      "Epoch 132/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 132: TrainLoss=0.0045  ValAcc=0.5750  F1=0.5580  Prec=0.5955  Rec=0.5750\n",
      "Epoch 133/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.24it/s]\n",
      "Epoch 133: TrainLoss=0.0012  ValAcc=0.5775  F1=0.5568  Prec=0.6012  Rec=0.5775\n",
      "Epoch 134/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.85it/s]\n",
      "Epoch 134: TrainLoss=0.0026  ValAcc=0.5900  F1=0.5642  Prec=0.6038  Rec=0.5900\n",
      "Epoch 135/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 135: TrainLoss=0.0020  ValAcc=0.5825  F1=0.5650  Prec=0.6163  Rec=0.5825\n",
      "Epoch 136/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.03it/s]\n",
      "Epoch 136: TrainLoss=0.0007  ValAcc=0.5825  F1=0.5629  Prec=0.6119  Rec=0.5825\n",
      "Epoch 137/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.80it/s]\n",
      "Epoch 137: TrainLoss=0.0035  ValAcc=0.5975  F1=0.5769  Prec=0.6170  Rec=0.5975\n",
      "Epoch 138/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.03it/s]\n",
      "Epoch 138: TrainLoss=0.0008  ValAcc=0.6000  F1=0.5814  Prec=0.6319  Rec=0.6000\n",
      "Epoch 139/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.07it/s]\n",
      "Epoch 139: TrainLoss=0.0031  ValAcc=0.5875  F1=0.5701  Prec=0.6205  Rec=0.5875\n",
      "Epoch 140/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 140: TrainLoss=0.0034  ValAcc=0.5825  F1=0.5702  Prec=0.6269  Rec=0.5825\n",
      "Epoch 141/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.89it/s]\n",
      "Epoch 141: TrainLoss=0.0001  ValAcc=0.5800  F1=0.5687  Prec=0.6237  Rec=0.5800\n",
      "Epoch 142/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.28it/s]\n",
      "Epoch 142: TrainLoss=0.0014  ValAcc=0.5875  F1=0.5760  Prec=0.6298  Rec=0.5875\n",
      "Epoch 143/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.07it/s]\n",
      "Epoch 143: TrainLoss=0.0006  ValAcc=0.5825  F1=0.5699  Prec=0.6248  Rec=0.5825\n",
      "Epoch 144/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.90it/s]\n",
      "Epoch 144: TrainLoss=0.0018  ValAcc=0.5900  F1=0.5760  Prec=0.6333  Rec=0.5900\n",
      "Epoch 145/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.92it/s]\n",
      "Epoch 145: TrainLoss=0.0015  ValAcc=0.5875  F1=0.5680  Prec=0.6254  Rec=0.5875\n",
      "Epoch 146/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.03it/s]\n",
      "Epoch 146: TrainLoss=0.0003  ValAcc=0.5850  F1=0.5672  Prec=0.6244  Rec=0.5850\n",
      "Epoch 147/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.02it/s]\n",
      "Epoch 147: TrainLoss=0.0027  ValAcc=0.5950  F1=0.5718  Prec=0.6306  Rec=0.5950\n",
      "Epoch 148/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.06it/s]\n",
      "Epoch 148: TrainLoss=0.0022  ValAcc=0.5950  F1=0.5771  Prec=0.6334  Rec=0.5950\n",
      "Epoch 149/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 12.03it/s]\n",
      "Epoch 149: TrainLoss=0.0003  ValAcc=0.5850  F1=0.5682  Prec=0.6282  Rec=0.5850\n",
      "Epoch 150/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.81it/s]\n",
      "Epoch 150: TrainLoss=0.0018  ValAcc=0.5900  F1=0.5731  Prec=0.6300  Rec=0.5900\n",
      "Epoch 151/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 151: TrainLoss=0.0008  ValAcc=0.5925  F1=0.5755  Prec=0.6399  Rec=0.5925\n",
      "Epoch 152/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.71it/s]\n",
      "Epoch 152: TrainLoss=0.0005  ValAcc=0.5800  F1=0.5636  Prec=0.6307  Rec=0.5800\n",
      "Epoch 153/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.86it/s]\n",
      "Epoch 153: TrainLoss=0.0018  ValAcc=0.5725  F1=0.5577  Prec=0.6212  Rec=0.5725\n",
      "Epoch 154/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.72it/s]\n",
      "Epoch 154: TrainLoss=0.0001  ValAcc=0.5750  F1=0.5604  Prec=0.6217  Rec=0.5750\n",
      "Epoch 155/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.67it/s]\n",
      "Epoch 155: TrainLoss=0.0017  ValAcc=0.5725  F1=0.5582  Prec=0.6227  Rec=0.5725\n",
      "Epoch 156/180 [Train]: 100%|██████████████████| 113/113 [00:09<00:00, 11.83it/s]\n",
      "Epoch 156: TrainLoss=0.0005  ValAcc=0.5750  F1=0.5599  Prec=0.6256  Rec=0.5750\n",
      "⏹️ Early stopping at epoch 156\n",
      "🏆 Best Validation Accuracy: 0.6100\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONPATH=/workspace/python_packages:$PYTHONPATH\n",
    "\n",
    "!python external_repos/mamba-code/train_mamba.py \\\n",
    "  --esc50_path data/ESC-50 \\\n",
    "  --batch_size 32 \\\n",
    "  --workers 2 \\\n",
    "  --lr 1e-4 \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --epochs 180 \\\n",
    "  --patience 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe52e63-e651-471b-ba00-4d520b8d417a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
